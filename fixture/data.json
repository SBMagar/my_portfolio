[{"model": "contenttypes.contenttype", "pk": 1, "fields": {"app_label": "admin", "model": "logentry"}}, {"model": "contenttypes.contenttype", "pk": 2, "fields": {"app_label": "auth", "model": "permission"}}, {"model": "contenttypes.contenttype", "pk": 3, "fields": {"app_label": "auth", "model": "group"}}, {"model": "contenttypes.contenttype", "pk": 4, "fields": {"app_label": "auth", "model": "user"}}, {"model": "contenttypes.contenttype", "pk": 5, "fields": {"app_label": "contenttypes", "model": "contenttype"}}, {"model": "contenttypes.contenttype", "pk": 6, "fields": {"app_label": "sessions", "model": "session"}}, {"model": "contenttypes.contenttype", "pk": 7, "fields": {"app_label": "portfolio", "model": "contact"}}, {"model": "contenttypes.contenttype", "pk": 8, "fields": {"app_label": "blogs", "model": "category_post"}}, {"model": "contenttypes.contenttype", "pk": 9, "fields": {"app_label": "blogs", "model": "post"}}, {"model": "contenttypes.contenttype", "pk": 10, "fields": {"app_label": "blogs", "model": "comment"}}, {"model": "contenttypes.contenttype", "pk": 11, "fields": {"app_label": "works", "model": "category_work"}}, {"model": "contenttypes.contenttype", "pk": 12, "fields": {"app_label": "works", "model": "work"}}, {"model": "contenttypes.contenttype", "pk": 13, "fields": {"app_label": "django_summernote", "model": "attachment"}}, {"model": "contenttypes.contenttype", "pk": 14, "fields": {"app_label": "taggit", "model": "tag"}}, {"model": "contenttypes.contenttype", "pk": 15, "fields": {"app_label": "taggit", "model": "taggeditem"}}, {"model": "contenttypes.contenttype", "pk": 16, "fields": {"app_label": "portfolio", "model": "experience"}}, {"model": "contenttypes.contenttype", "pk": 17, "fields": {"app_label": "portfolio", "model": "skill"}}, {"model": "contenttypes.contenttype", "pk": 18, "fields": {"app_label": "experiences", "model": "education"}}, {"model": "contenttypes.contenttype", "pk": 19, "fields": {"app_label": "experiences", "model": "employment"}}, {"model": "sessions.session", "pk": "3xb9cnm2a5u0q5dqi80vqxt46lik5gh4", "fields": {"session_data": ".eJxVjDsOwjAQBe_iGln-fyjpcwZr7fXiAEqkOKkQd0eWUkD7Zua9WYJjb-nodUszsiuT7PK7ZSjPugyAD1juKy_rsm9z5kPhJ-18WrG-bqf7d9Cgt1FbROmtVJlAVBGsLhizVF57VMpUB4GMk4TOkCGvCYKLlqIJXhTtiX2-5FA3uQ:1osdMu:ORkjjn1XkDmlIWRq21esVH4gOiJsP00AbFjIg6JYCBc", "expire_date": "2022-11-23T05:11:20.697Z"}}, {"model": "sessions.session", "pk": "6fszt1r94wpz6oo79dqducxy38kcpcyk", "fields": {"session_data": "MjczOTY5MTQzZDQwN2RlYzdmMTIyZjc1OWQ1ZDg5OTkwMzVlM2I3ZDp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJlZmE3NDRlMDkyZTgwMmVhN2JjMjNlNDg2ZjMwZTY2ZTk4YjVmZjg1In0=", "expire_date": "2021-12-24T06:59:57.063Z"}}, {"model": "sessions.session", "pk": "70pz11airizc7b0n3eqtjukxi9wp9pnl", "fields": {"session_data": ".eJxVjDsOwjAQBe_iGln-fyjpcwZr7fXiAEqkOKkQd0eWUkD7Zua9WYJjb-nodUszsiuT7PK7ZSjPugyAD1juKy_rsm9z5kPhJ-18WrG-bqf7d9Cgt1FbROmtVJlAVBGsLhizVF57VMpUB4GMk4TOkCGvCYKLlqIJXhTtiX2-5FA3uQ:1oGIGt:XVIVN1V0YyQ_e_P_XyPZXWgDhf_pJ9wyvXdOLkOjV3o", "expire_date": "2022-08-09T10:58:39.616Z"}}, {"model": "sessions.session", "pk": "7bgkbg0rcj6dg7zd5vpwv2pla537cd9d", "fields": {"session_data": "MjczOTY5MTQzZDQwN2RlYzdmMTIyZjc1OWQ1ZDg5OTkwMzVlM2I3ZDp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJlZmE3NDRlMDkyZTgwMmVhN2JjMjNlNDg2ZjMwZTY2ZTk4YjVmZjg1In0=", "expire_date": "2021-06-10T13:57:35.307Z"}}, {"model": "sessions.session", "pk": "7f0kn5z2asqvkdqhhz7e43gmq9z6onhj", "fields": {"session_data": "MjczOTY5MTQzZDQwN2RlYzdmMTIyZjc1OWQ1ZDg5OTkwMzVlM2I3ZDp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJlZmE3NDRlMDkyZTgwMmVhN2JjMjNlNDg2ZjMwZTY2ZTk4YjVmZjg1In0=", "expire_date": "2021-06-09T09:04:34.148Z"}}, {"model": "sessions.session", "pk": "7x507rdd5dv8qhmlr7emafydo3zqgd6g", "fields": {"session_data": ".eJxVjDsOwjAQBe_iGln-fyjpcwZr7fXiAEqkOKkQd0eWUkD7Zua9WYJjb-nodUszsiuT7PK7ZSjPugyAD1juKy_rsm9z5kPhJ-18WrG-bqf7d9Cgt1FbROmtVJlAVBGsLhizVF57VMpUB4GMk4TOkCGvCYKLlqIJXhTtiX2-5FA3uQ:1oZu6s:TQ1D2b3QWOyDmyenJ8A4v3aWUn1Q5exmJPEa7TSTtmU", "expire_date": "2022-10-02T13:13:22.498Z"}}, {"model": "sessions.session", "pk": "9hcm0obawgt7aqip8d7lm0hdhloqeooe", "fields": {"session_data": "MjczOTY5MTQzZDQwN2RlYzdmMTIyZjc1OWQ1ZDg5OTkwMzVlM2I3ZDp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJlZmE3NDRlMDkyZTgwMmVhN2JjMjNlNDg2ZjMwZTY2ZTk4YjVmZjg1In0=", "expire_date": "2021-09-21T04:31:47.906Z"}}, {"model": "sessions.session", "pk": "ek22trduyn50gi6t521fmsiqk8kwoywz", "fields": {"session_data": "MjczOTY5MTQzZDQwN2RlYzdmMTIyZjc1OWQ1ZDg5OTkwMzVlM2I3ZDp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJlZmE3NDRlMDkyZTgwMmVhN2JjMjNlNDg2ZjMwZTY2ZTk4YjVmZjg1In0=", "expire_date": "2021-08-07T12:19:50.710Z"}}, {"model": "sessions.session", "pk": "eqdznpga66mf4omzx2e6ztfm4c60342r", "fields": {"session_data": "MjczOTY5MTQzZDQwN2RlYzdmMTIyZjc1OWQ1ZDg5OTkwMzVlM2I3ZDp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJlZmE3NDRlMDkyZTgwMmVhN2JjMjNlNDg2ZjMwZTY2ZTk4YjVmZjg1In0=", "expire_date": "2021-07-06T09:33:56.464Z"}}, {"model": "sessions.session", "pk": "f2wf4n2nfvt2vrnraew32ehf0d2jb8dm", "fields": {"session_data": "MjczOTY5MTQzZDQwN2RlYzdmMTIyZjc1OWQ1ZDg5OTkwMzVlM2I3ZDp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJlZmE3NDRlMDkyZTgwMmVhN2JjMjNlNDg2ZjMwZTY2ZTk4YjVmZjg1In0=", "expire_date": "2022-02-08T19:52:04.881Z"}}, {"model": "sessions.session", "pk": "gdoy7gqqvwkataw6xboq4o6527f5ehh3", "fields": {"session_data": "MjczOTY5MTQzZDQwN2RlYzdmMTIyZjc1OWQ1ZDg5OTkwMzVlM2I3ZDp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJlZmE3NDRlMDkyZTgwMmVhN2JjMjNlNDg2ZjMwZTY2ZTk4YjVmZjg1In0=", "expire_date": "2021-07-06T09:33:57.859Z"}}, {"model": "sessions.session", "pk": "gmw9yehpbvdmrri2v014lurh8qbe2qy0", "fields": {"session_data": "MjczOTY5MTQzZDQwN2RlYzdmMTIyZjc1OWQ1ZDg5OTkwMzVlM2I3ZDp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJlZmE3NDRlMDkyZTgwMmVhN2JjMjNlNDg2ZjMwZTY2ZTk4YjVmZjg1In0=", "expire_date": "2022-01-24T09:00:13.481Z"}}, {"model": "sessions.session", "pk": "h47cm130sclwiv3m7yzj5yc6rr92c2l3", "fields": {"session_data": "MjczOTY5MTQzZDQwN2RlYzdmMTIyZjc1OWQ1ZDg5OTkwMzVlM2I3ZDp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJlZmE3NDRlMDkyZTgwMmVhN2JjMjNlNDg2ZjMwZTY2ZTk4YjVmZjg1In0=", "expire_date": "2021-06-27T12:59:44.784Z"}}, {"model": "sessions.session", "pk": "ib644e1qv113lhgh5sr8yabo1zwrcx2z", "fields": {"session_data": "MjczOTY5MTQzZDQwN2RlYzdmMTIyZjc1OWQ1ZDg5OTkwMzVlM2I3ZDp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJlZmE3NDRlMDkyZTgwMmVhN2JjMjNlNDg2ZjMwZTY2ZTk4YjVmZjg1In0=", "expire_date": "2021-06-09T01:49:06.050Z"}}, {"model": "sessions.session", "pk": "kdpbaq2q6whptytavmzopn656ab9sd0h", "fields": {"session_data": "MjczOTY5MTQzZDQwN2RlYzdmMTIyZjc1OWQ1ZDg5OTkwMzVlM2I3ZDp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJlZmE3NDRlMDkyZTgwMmVhN2JjMjNlNDg2ZjMwZTY2ZTk4YjVmZjg1In0=", "expire_date": "2021-07-20T04:54:35.724Z"}}, {"model": "sessions.session", "pk": "lchzncyznmz726azi6bvn37q4jo47ri6", "fields": {"session_data": "MjczOTY5MTQzZDQwN2RlYzdmMTIyZjc1OWQ1ZDg5OTkwMzVlM2I3ZDp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJlZmE3NDRlMDkyZTgwMmVhN2JjMjNlNDg2ZjMwZTY2ZTk4YjVmZjg1In0=", "expire_date": "2021-09-28T21:32:37.267Z"}}, {"model": "sessions.session", "pk": "liv7gpoe6vpna4vfy7t2l277136qgs51", "fields": {"session_data": "MjczOTY5MTQzZDQwN2RlYzdmMTIyZjc1OWQ1ZDg5OTkwMzVlM2I3ZDp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJlZmE3NDRlMDkyZTgwMmVhN2JjMjNlNDg2ZjMwZTY2ZTk4YjVmZjg1In0=", "expire_date": "2021-06-18T12:26:55.106Z"}}, {"model": "sessions.session", "pk": "mqye4986lro203je9tgjr68x6dlb367s", "fields": {"session_data": "MjczOTY5MTQzZDQwN2RlYzdmMTIyZjc1OWQ1ZDg5OTkwMzVlM2I3ZDp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJlZmE3NDRlMDkyZTgwMmVhN2JjMjNlNDg2ZjMwZTY2ZTk4YjVmZjg1In0=", "expire_date": "2021-08-30T21:07:20.615Z"}}, {"model": "sessions.session", "pk": "nbe7rw4ee09ie21pk6f6hej2p78oeu3s", "fields": {"session_data": ".eJxVjDsOwjAQBe_iGln-fyjpcwZr7fXiAEqkOKkQd0eWUkD7Zua9WYJjb-nodUszsiuT7PK7ZSjPugyAD1juKy_rsm9z5kPhJ-18WrG-bqf7d9Cgt1FbROmtVJlAVBGsLhizVF57VMpUB4GMk4TOkCGvCYKLlqIJXhTtiX2-5FA3uQ:1noJSR:Pf0zHIzoNB3eshAFvz-ispjZ77rYocmRvNlflqEVk9c", "expire_date": "2022-05-24T06:34:55.183Z"}}, {"model": "sessions.session", "pk": "nmv2qupzoi9y2esxh1a30lkb4z9etpi4", "fields": {"session_data": ".eJxVjDsOwjAQBe_iGln-fyjpcwZr7fXiAEqkOKkQd0eWUkD7Zua9WYJjb-nodUszsiuT7PK7ZSjPugyAD1juKy_rsm9z5kPhJ-18WrG-bqf7d9Cgt1FbROmtVJlAVBGsLhizVF57VMpUB4GMk4TOkCGvCYKLlqIJXhTtiX2-5FA3uQ:1nJZmJ:eTZvQsMJlyHzwV6dtO6-sXoChVRLyR__bMhfLSSbYH8", "expire_date": "2022-02-28T11:44:23.861Z"}}, {"model": "sessions.session", "pk": "nx60nslqdfpyeg15bi06jn9pmddazihp", "fields": {"session_data": ".eJxVjDsOwjAQBe_iGln-fyjpcwZr7fXiAEqkOKkQd0eWUkD7Zua9WYJjb-nodUszsiuT7PK7ZSjPugyAD1juKy_rsm9z5kPhJ-18WrG-bqf7d9Cgt1FbROmtVJlAVBGsLhizVF57VMpUB4GMk4TOkCGvCYKLlqIJXhTtiX2-5FA3uQ:1oa9sw:EZSEVyFTq-OCzSyjAVX4ybd2w--5N9keWSU_P2LnXGA", "expire_date": "2022-10-03T06:04:02.461Z"}}, {"model": "sessions.session", "pk": "o9kreth2mj3yimp69m4e425xi4lbh09f", "fields": {"session_data": ".eJxVjDsOwjAQBe_iGln-fyjpcwZr7fXiAEqkOKkQd0eWUkD7Zua9WYJjb-nodUszsiuT7PK7ZSjPugyAD1juKy_rsm9z5kPhJ-18WrG-bqf7d9Cgt1FbROmtVJlAVBGsLhizVF57VMpUB4GMk4TOkCGvCYKLlqIJXhTtiX2-5FA3uQ:1nHiUM:QH667orcuuTihZToY0LlvECrNx_Jh7YCWHL5Dx4ses0", "expire_date": "2022-02-23T08:38:10.698Z"}}, {"model": "sessions.session", "pk": "okb3t5gp2xe12ffs8h5skfugxngp3b1j", "fields": {"session_data": "MjczOTY5MTQzZDQwN2RlYzdmMTIyZjc1OWQ1ZDg5OTkwMzVlM2I3ZDp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJlZmE3NDRlMDkyZTgwMmVhN2JjMjNlNDg2ZjMwZTY2ZTk4YjVmZjg1In0=", "expire_date": "2021-08-16T15:45:09.935Z"}}, {"model": "sessions.session", "pk": "q8fmi24ib79o272dguo7t9pywhdc4ve7", "fields": {"session_data": ".eJxVjDsOwjAQBe_iGln-fyjpcwZr7fXiAEqkOKkQd0eWUkD7Zua9WYJjb-nodUszsiuT7PK7ZSjPugyAD1juKy_rsm9z5kPhJ-18WrG-bqf7d9Cgt1FbROmtVJlAVBGsLhizVF57VMpUB4GMk4TOkCGvCYKLlqIJXhTtiX2-5FA3uQ:1oDq8J:boteF3ezLZw1j7Syi49sQ8H0_UlXAbM17_d7QiuovtA", "expire_date": "2022-08-02T16:31:39.061Z"}}, {"model": "sessions.session", "pk": "qo9rjlotvs6tj13w0bysi6qpojeridxt", "fields": {"session_data": "MjczOTY5MTQzZDQwN2RlYzdmMTIyZjc1OWQ1ZDg5OTkwMzVlM2I3ZDp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJlZmE3NDRlMDkyZTgwMmVhN2JjMjNlNDg2ZjMwZTY2ZTk4YjVmZjg1In0=", "expire_date": "2021-11-28T19:47:16.028Z"}}, {"model": "sessions.session", "pk": "sxz61qg3w7hytsu7py1mtqiyyrjcr6tc", "fields": {"session_data": "MjczOTY5MTQzZDQwN2RlYzdmMTIyZjc1OWQ1ZDg5OTkwMzVlM2I3ZDp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJlZmE3NDRlMDkyZTgwMmVhN2JjMjNlNDg2ZjMwZTY2ZTk4YjVmZjg1In0=", "expire_date": "2021-06-09T07:56:54.801Z"}}, {"model": "sessions.session", "pk": "y0ogq5b9xomklbw87gunzkphgtrato6v", "fields": {"session_data": ".eJxVjDsOwjAQBe_iGlmJ15-Ykp4zWOvdDQ4gR4qTCnF3iJQC2jcz76USbmtJW5MlTazOyqjT75aRHlJ3wHest1nTXNdlynpX9EGbvs4sz8vh_h0UbOVbDyChB-QeTM4erZdMjqCLPHpAoBAdWjZks8UYOhYZHQyBGYyJQUi9P_DcOGE:1oDmCd:j3fZ2bpO9S5slibHHZ7vnltiaM9eRTduj3EYnIKI1oY", "expire_date": "2022-08-02T12:19:51.030Z"}}, {"model": "sessions.session", "pk": "z815p3fe60z762rmo9jor1skrzp5cjcv", "fields": {"session_data": "MjczOTY5MTQzZDQwN2RlYzdmMTIyZjc1OWQ1ZDg5OTkwMzVlM2I3ZDp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJlZmE3NDRlMDkyZTgwMmVhN2JjMjNlNDg2ZjMwZTY2ZTk4YjVmZjg1In0=", "expire_date": "2021-06-10T22:58:50.527Z"}}, {"model": "portfolio.contact", "pk": 1, "fields": {"name": "Sagar Budhathoki", "email": "sbmagar.sbm55@gmail.com", "subject": "Opportunities", "message": "Are you available??", "created": "2021-05-26T07:56:21.238Z"}}, {"model": "portfolio.contact", "pk": 2, "fields": {"name": "ewfsad", "email": "sdfasd@gmail.com", "subject": "sdfsad", "message": "sadfasdf", "created": "2022-07-21T08:41:55.825Z"}}, {"model": "portfolio.contact", "pk": 3, "fields": {"name": "rcrspccfdo", "email": "lwyzane@outlook.com", "subject": "rcrspccfdo", "message": "Sagar Budhathoki - Portfolio\r\nrcrspccfdo http://www.g67iq96k4711g9630m4n3zowjq1igei3s.org/\r\n<a href=\"http://www.g67iq96k4711g9630m4n3zowjq1igei3s.org/\">arcrspccfdo</a>\r\n[url=http://www.g67iq96k4711g9630m4n3zowjq1igei3s.org/]urcrspccfdo[/url]", "created": "2022-08-25T00:27:36.207Z"}}, {"model": "blogs.category_post", "pk": 1, "fields": {"name": "ai-ml", "slug": "ai-ml"}}, {"model": "blogs.category_post", "pk": 2, "fields": {"name": "devops", "slug": "devops"}}, {"model": "blogs.category_post", "pk": 3, "fields": {"name": "Linuxify", "slug": "linuxify"}}, {"model": "blogs.comment", "pk": 1, "fields": {"post": 4, "name": "Joseph", "email": "josph@joseph.com", "body": "Great tutorial ! But not for beginner though.", "created": "2021-06-04T14:09:12.945Z", "updated": "2021-06-04T14:09:12.945Z", "active": true, "parent": null}}, {"model": "works.category_work", "pk": 1, "fields": {"name": "django-special", "slug": "django-special"}}, {"model": "works.category_work", "pk": 2, "fields": {"name": "ml-project", "slug": "ml-project"}}, {"model": "works.category_work", "pk": 3, "fields": {"name": "web-scraping", "slug": "web-scraping"}}, {"model": "works.category_work", "pk": 4, "fields": {"name": "static-application", "slug": "static-application"}}, {"model": "works.category_work", "pk": 5, "fields": {"name": "others", "slug": "others"}}, {"model": "experiences.employment", "pk": 1, "fields": {"name": "VolgAI", "position": "AI Software Developer(Python) - Contract", "start_year": "2021", "start_month": "Feb", "end_year": "2021", "end_month": "Aug", "current_status": false, "end_date_value": "Aug, 2021", "description": "#### Achievements/Tasks\r\n- [x] Chatbot Development from scratch with RASA Stack(NLP)\r\n- [x] Model Optimization, pipeline configurations, rasa-x integration\r\n- [x] Speech-to-Text integration to rasa chatbot\r\n- [x] Docker/docker-compose deployment with supervisord, nginx, postgres, rabbitmq...", "town": "New Baneshwor", "url": "https://volgai.com"}}, {"model": "experiences.employment", "pk": 2, "fields": {"name": "Genese Cloud Academy", "position": "AWS AI/ML Interestship (4-months program)", "start_year": "2020", "start_month": "Oct", "end_year": "2021", "end_month": "Jan", "current_status": false, "end_date_value": "Jan, 2021", "description": "#### Achievements/Tasks\r\n- [x] Worked on various AWS services: EC2, S3, RedShift, dynamodb, SQLs, Load Balancer, Lambda, etc\r\n- [x] Developed weatherbot using Lex\r\n- [x] Other services: Rekognition, Polly, Apache MXNet, Pytorch, etc", "town": "Kathmandu", "url": "https://genesecloud.academy"}}, {"model": "experiences.employment", "pk": 3, "fields": {"name": "IBZ Networks Pvt. Ltd.", "position": "AI Research Associate | Django Developer", "start_year": "2020", "start_month": "Jan", "end_year": "2020", "end_month": "Oct", "current_status": false, "end_date_value": "Oct, 2020", "description": "#### Achievements/Tasks\r\n- [x] Developed fully functioning **ffmpeg/live555** RTSP protocol (\"*Image process (CCTV, NVR) window app development*\")\r\n- [x] Developed Sensor Operator Server UI with **Django** (\"*Black Ice Detection System*\")\r\n- [x] **UDP Server**, **MariaDB** for sensor database(\"*Black Ice Detection System*\"), **decoding** of sensors' input data\r\n- [x] Worked on **Data processing**, **Web Scraping**, **Model Development**, **Data Visualization** with **Plotly** etc.", "town": "Kathmandu", "url": "https://lksystem.com"}}, {"model": "experiences.employment", "pk": 4, "fields": {"name": "Cloudyfox Technology Pvt. Ltd.", "position": "DevOps Engineer", "start_year": "2021", "start_month": "Sep", "end_year": "", "end_month": "", "current_status": true, "end_date_value": "Present", "description": "#### Achievements/Tasks\r\n- [x] Creating, configuring and maintaining Infrastructure on **AWS** including **VPC**, **EC2**, **RDS**, **ECS**, **S3**, **Lambda**, **API Gateway**, **Route53**, **ACM**, **Cognito**, **CloudFront**, **CloudWatch** and **IAM**.\r\n- [x] **Kubernetes** cloud/server deployment with **Helm Chart**.\r\n- [x] Managing multiple environments and infrastructures with **IaC** using **Terraform**, also worked on **AWS CDK** with **Python**.\r\n- [x] **OpenVPN** and ELK stack configurations on EC2 (**ElasticSearch**, **LogStash**, **Kibana**, **Filebeat**).\r\n- [x] Implementation of **CI/CD** with **GitLab**, **Docker**, **AWS SAM**, etc.\r\n- [x] Autoscaling **GitLab Runner** on EC2 with **docker-machine**.", "town": "Anamnagar", "url": "https://cloudyfox.io"}}, {"model": "experiences.employment", "pk": 5, "fields": {"name": "Freelance | Personal", "position": "Python Developer | AIML", "start_year": "2020", "start_month": "Jun", "end_year": "", "end_month": "", "current_status": true, "end_date_value": "Present", "description": "#### Achievements/Tasks\r\n- [x] Worked on Text-to-Image using Multimodal**(CLIP+VQGAN)** Architectures, MLOps platform like **wandb**, **Amazon Sagemaker**,  **Google Colab**, etc.\r\n- [x] **Web Scraping/Crawling** and **Automation** with **Python Scrapy**.\r\n- [x] Personal Portfolio site with **Django**, **Postgres**, **Docker**, **Nginx**, **Heroku**, and other various techs.", "town": "Kathmandu", "url": "https://budhathokisagar.com.np"}}, {"model": "experiences.employment", "pk": 6, "fields": {"name": "WRC", "position": "Student", "start_year": "2018", "start_month": "Jun", "end_year": "2019", "end_month": "Nov", "current_status": false, "end_date_value": "Nov, 2019", "description": "#### College Major Project -- ***Text-to-Image Synthesis***\r\n- [x] Developed **GAN** model to generate plausible image of flowers by giving input as text description of flowers.\r\n- [x] **Generator**, **Discriminator**, **text embeddings**, **optimizations**, **loss calculations**, etc.\r\n\r\n#### College Minor Project -- ***e-Police: Online FIR System***\r\n- [x] **70%** Completed, a simple web based portal for online crime records management(**Python-Django**), **SQLite3**, **JS**, **HTML/CSS**", "town": "Pokhara", "url": "https://wrc.edu.np"}}, {"model": "django_summernote.attachment", "pk": 1, "fields": {"name": "Screenshot from 2021-04-02 22-27-52.png", "file": "django-summernote/2021-05-26/243e6bca-fb36-4c2b-9ffa-6039ffd1eb20.png", "uploaded": "2021-05-26T09:33:15.075Z"}}, {"model": "django_summernote.attachment", "pk": 2, "fields": {"name": "Screenshot from 2021-04-02 22-27-52.png", "file": "django-summernote/2021-05-26/8a6f250b-ea63-4793-a989-d49704437eb3.png", "uploaded": "2021-05-26T09:34:27.980Z"}}, {"model": "django_summernote.attachment", "pk": 3, "fields": {"name": "Screenshot from 2021-02-24 21-53-47.png", "file": "django-summernote/2021-05-26/3b27997b-05c1-45df-8c01-a7ef8bea69a8.png", "uploaded": "2021-05-26T13:49:42.152Z"}}, {"model": "django_summernote.attachment", "pk": 4, "fields": {"name": "raidfscrap3.png", "file": "django-summernote/2021-05-26/8475cf9c-052e-4581-b0d6-917260e523a0.png", "uploaded": "2021-05-26T13:56:24.606Z"}}, {"model": "django_summernote.attachment", "pk": 5, "fields": {"name": "raidfscrap3.png", "file": "django-summernote/2021-05-26/46158c72-8172-4db7-bc9b-e91b05edab71.png", "uploaded": "2021-05-26T14:30:07.447Z"}}, {"model": "django_summernote.attachment", "pk": 6, "fields": {"name": "Screenshot from 2021-02-24 21-53-47.png", "file": "django-summernote/2021-05-26/f7d3453e-5b7e-43db-9668-247ead994ecc.png", "uploaded": "2021-05-26T14:30:42.902Z"}}, {"model": "django_summernote.attachment", "pk": 7, "fields": {"name": "Screenshot from 2021-02-24 21-53-17.png", "file": "django-summernote/2021-05-26/62daa1c3-edf5-469c-be69-9d874a154503.png", "uploaded": "2021-05-26T14:31:01.167Z"}}, {"model": "django_summernote.attachment", "pk": 8, "fields": {"name": "plotly.png", "file": "django-summernote/2021-05-27/173afd7b-2a57-4ae7-8b16-44476fef4bfd.png", "uploaded": "2021-05-27T07:28:25.624Z"}}, {"model": "django_summernote.attachment", "pk": 9, "fields": {"name": "raidfscrap3.png", "file": "django-summernote/2021-05-27/b206cbe1-39ab-4c6d-87c2-e30768d45524.png", "uploaded": "2021-05-27T14:02:22.163Z"}}, {"model": "django_summernote.attachment", "pk": 10, "fields": {"name": "Screenshot from 2021-02-24 21-53-47.png", "file": "django-summernote/2021-05-27/39776977-bbc3-47b7-a971-22f73a5f0047.png", "uploaded": "2021-05-27T14:03:04.694Z"}}, {"model": "django_summernote.attachment", "pk": 11, "fields": {"name": "Screenshot from 2021-02-24 21-53-17.png", "file": "django-summernote/2021-05-27/4dbe85ef-6dfd-4072-8b82-cb49a1b2f9a5.png", "uploaded": "2021-05-27T14:03:19.902Z"}}, {"model": "django_summernote.attachment", "pk": 12, "fields": {"name": "raidfscrap3.png", "file": "django-summernote/2021-05-27/3baec02b-a570-4a6e-a952-daa2dcd1236c.png", "uploaded": "2021-05-27T15:48:25.724Z"}}, {"model": "django_summernote.attachment", "pk": 13, "fields": {"name": "Screenshot from 2021-02-24 21-53-17.png", "file": "django-summernote/2021-05-27/620401be-d54e-4359-9b22-e522107947fb.png", "uploaded": "2021-05-27T15:48:31.412Z"}}, {"model": "django_summernote.attachment", "pk": 14, "fields": {"name": "Screenshot from 2021-02-24 21-53-47.png", "file": "django-summernote/2021-05-27/a955cdf6-fe83-4786-9b56-35a25ad5bee6.png", "uploaded": "2021-05-27T15:49:08.403Z"}}, {"model": "django_summernote.attachment", "pk": 15, "fields": {"name": "raidfscrap3.png", "file": "django-summernote/2021-05-27/65c4b6de-eb34-4805-9733-c5efbec9bb77.png", "uploaded": "2021-05-27T16:20:33.328Z"}}, {"model": "django_summernote.attachment", "pk": 16, "fields": {"name": "Screenshot from 2021-02-24 21-53-17.png", "file": "django-summernote/2021-05-27/ef2b4dcc-e660-4e3f-ba81-22903b31cd83.png", "uploaded": "2021-05-27T16:20:57.701Z"}}, {"model": "django_summernote.attachment", "pk": 17, "fields": {"name": "Screenshot from 2021-02-24 21-53-17.png", "file": "django-summernote/2021-05-27/ba26a243-7e9c-4a19-a17d-b71727a74854.png", "uploaded": "2021-05-27T16:21:08.890Z"}}, {"model": "django_summernote.attachment", "pk": 18, "fields": {"name": "volgai_chatbot1.png", "file": "django-summernote/2021-05-27/35c9135c-c691-462d-b02c-a13e9db57c9c.png", "uploaded": "2021-05-27T17:35:01.802Z"}}, {"model": "django_summernote.attachment", "pk": 19, "fields": {"name": "Screenshot from 2021-02-24 21-53-17.png", "file": "media/django-summernote/2021-05-27/27a8f61e-b549-4577-bbb7-b0fa9136fd43_gcny1c", "uploaded": "2021-05-27T23:01:20.257Z"}}, {"model": "django_summernote.attachment", "pk": 20, "fields": {"name": "Screenshot from 2021-02-24 21-53-17.png", "file": "media/django-summernote/2021-05-27/d33ad5f7-1985-4fd1-9731-6904a5aecf7b_tzqp1i", "uploaded": "2021-05-27T23:01:35.116Z"}}, {"model": "django_summernote.attachment", "pk": 21, "fields": {"name": "raidfscrap3.png", "file": "media/django-summernote/2021-05-27/9a50b7f3-7022-44c9-a6bb-996f1756e965_looegr", "uploaded": "2021-05-27T23:02:14.212Z"}}, {"model": "django_summernote.attachment", "pk": 22, "fields": {"name": "volgai_chatbot1.png", "file": "media/django-summernote/2021-05-27/8bb92e4d-ccac-49ee-bea8-aa11edcfcb6a_ounozt", "uploaded": "2021-05-27T23:07:40.241Z"}}, {"model": "django_summernote.attachment", "pk": 23, "fields": {"name": "plotly.png", "file": "media/django-summernote/2021-05-27/fa94a85f-3d82-47e6-a7f6-0f95ecc8e64a_qjo0o3", "uploaded": "2021-05-27T23:08:25.962Z"}}, {"model": "django_summernote.attachment", "pk": 24, "fields": {"name": "ezgif.com-gif-maker (4).gif", "file": "media/django-summernote/2021-08-02/e1361e17-1d1b-43e3-bbda-1448cd9a5a1d_kxoj01", "uploaded": "2021-08-02T17:56:54.639Z"}}, {"model": "django_summernote.attachment", "pk": 25, "fields": {"name": "chatbot.png", "file": "media/django-summernote/2021-08-25/9c2816b6-2c31-44a2-9af4-d3632f6e70c8_tacaug", "uploaded": "2021-08-25T21:14:58.379Z"}}, {"model": "django_summernote.attachment", "pk": 26, "fields": {"name": "chatbot2.png", "file": "media/django-summernote/2021-08-25/c0e3a644-44ec-4b0d-bf9c-47790a548fcc_wygzp2", "uploaded": "2021-08-25T21:15:13.002Z"}}, {"model": "django_summernote.attachment", "pk": 27, "fields": {"name": "Screenshot from 2021-03-12 16-00-28.png", "file": "media/django-summernote/2021-08-25/4f88de93-27cc-495b-bafb-16fcc4ec9cc3_s2y2az", "uploaded": "2021-08-25T21:15:57.476Z"}}, {"model": "django_summernote.attachment", "pk": 28, "fields": {"name": "Screenshot from 2021-03-12 16-00-28.png", "file": "media/django-summernote/2021-08-25/5adfb73a-3a2c-4956-8762-90cdb6051e9f_migdu1", "uploaded": "2021-08-25T21:17:20.096Z"}}, {"model": "django_summernote.attachment", "pk": 29, "fields": {"name": "TemperatureGraph.PNG", "file": "media/django-summernote/2021-08-25/2c37fc1f-f9f9-4f62-a81d-b16082a3fbe6_va5jf0", "uploaded": "2021-08-25T21:32:36.348Z"}}, {"model": "django_summernote.attachment", "pk": 30, "fields": {"name": "OperatorManagerLists.PNG", "file": "media/django-summernote/2021-08-25/2446634c-cd50-447a-85a4-c05841ac9821_yruzl9", "uploaded": "2021-08-25T21:33:12.589Z"}}, {"model": "django_summernote.attachment", "pk": 31, "fields": {"name": "noise.jpeg", "file": "media/django-summernote/2021-08-25/f9932f2b-a2c4-4e80-93d0-691edf030145_gvpn5t", "uploaded": "2021-08-25T21:42:35.561Z"}}, {"model": "django_summernote.attachment", "pk": 32, "fields": {"name": "output.jpeg", "file": "media/django-summernote/2021-08-25/a641a9d3-789a-46bb-a0c8-c42203c67385_yrkby0", "uploaded": "2021-08-25T21:45:16.854Z"}}, {"model": "django_summernote.attachment", "pk": 33, "fields": {"name": "Simple Technology Blog Banner.jpg", "file": "media/django-summernote/2022-02-11/aec00284-0d46-45c9-82c4-8152c235862f_x4shmh", "uploaded": "2022-02-11T08:59:26.256Z"}}, {"model": "django_summernote.attachment", "pk": 34, "fields": {"name": "OpenVPN-1png.png", "file": "media/django-summernote/2022-02-14/22cf6e75-7264-4429-9efe-17c24d1d34ae_rnfttn", "uploaded": "2022-02-14T07:17:23.140Z"}}, {"model": "django_summernote.attachment", "pk": 35, "fields": {"name": "OpenVPN-2.png", "file": "media/django-summernote/2022-02-14/ca979e3e-0fe0-42cc-b765-f5d570011a8d_ygrzjr", "uploaded": "2022-02-14T07:17:38.587Z"}}, {"model": "django_summernote.attachment", "pk": 36, "fields": {"name": "Selection_006.png", "file": "media/django-summernote/2022-02-14/4694a722-c6dc-447c-9f97-cabf2bc89ed7_fwggor", "uploaded": "2022-02-14T07:18:06.970Z"}}, {"model": "django_summernote.attachment", "pk": 37, "fields": {"name": "Selection_007.png", "file": "media/django-summernote/2022-02-14/79ec66c7-fc3d-47ba-9c4b-8e1f17d890e4_cdgqlt", "uploaded": "2022-02-14T07:18:17.236Z"}}, {"model": "auth.permission", "pk": 1, "fields": {"name": "Can add log entry", "content_type": ["admin", "logentry"], "codename": "add_logentry"}}, {"model": "auth.permission", "pk": 2, "fields": {"name": "Can change log entry", "content_type": ["admin", "logentry"], "codename": "change_logentry"}}, {"model": "auth.permission", "pk": 3, "fields": {"name": "Can delete log entry", "content_type": ["admin", "logentry"], "codename": "delete_logentry"}}, {"model": "auth.permission", "pk": 4, "fields": {"name": "Can view log entry", "content_type": ["admin", "logentry"], "codename": "view_logentry"}}, {"model": "auth.permission", "pk": 5, "fields": {"name": "Can add permission", "content_type": ["auth", "permission"], "codename": "add_permission"}}, {"model": "auth.permission", "pk": 6, "fields": {"name": "Can change permission", "content_type": ["auth", "permission"], "codename": "change_permission"}}, {"model": "auth.permission", "pk": 7, "fields": {"name": "Can delete permission", "content_type": ["auth", "permission"], "codename": "delete_permission"}}, {"model": "auth.permission", "pk": 8, "fields": {"name": "Can view permission", "content_type": ["auth", "permission"], "codename": "view_permission"}}, {"model": "auth.permission", "pk": 9, "fields": {"name": "Can add group", "content_type": ["auth", "group"], "codename": "add_group"}}, {"model": "auth.permission", "pk": 10, "fields": {"name": "Can change group", "content_type": ["auth", "group"], "codename": "change_group"}}, {"model": "auth.permission", "pk": 11, "fields": {"name": "Can delete group", "content_type": ["auth", "group"], "codename": "delete_group"}}, {"model": "auth.permission", "pk": 12, "fields": {"name": "Can view group", "content_type": ["auth", "group"], "codename": "view_group"}}, {"model": "auth.permission", "pk": 13, "fields": {"name": "Can add user", "content_type": ["auth", "user"], "codename": "add_user"}}, {"model": "auth.permission", "pk": 14, "fields": {"name": "Can change user", "content_type": ["auth", "user"], "codename": "change_user"}}, {"model": "auth.permission", "pk": 15, "fields": {"name": "Can delete user", "content_type": ["auth", "user"], "codename": "delete_user"}}, {"model": "auth.permission", "pk": 16, "fields": {"name": "Can view user", "content_type": ["auth", "user"], "codename": "view_user"}}, {"model": "auth.permission", "pk": 17, "fields": {"name": "Can add content type", "content_type": ["contenttypes", "contenttype"], "codename": "add_contenttype"}}, {"model": "auth.permission", "pk": 18, "fields": {"name": "Can change content type", "content_type": ["contenttypes", "contenttype"], "codename": "change_contenttype"}}, {"model": "auth.permission", "pk": 19, "fields": {"name": "Can delete content type", "content_type": ["contenttypes", "contenttype"], "codename": "delete_contenttype"}}, {"model": "auth.permission", "pk": 20, "fields": {"name": "Can view content type", "content_type": ["contenttypes", "contenttype"], "codename": "view_contenttype"}}, {"model": "auth.permission", "pk": 21, "fields": {"name": "Can add session", "content_type": ["sessions", "session"], "codename": "add_session"}}, {"model": "auth.permission", "pk": 22, "fields": {"name": "Can change session", "content_type": ["sessions", "session"], "codename": "change_session"}}, {"model": "auth.permission", "pk": 23, "fields": {"name": "Can delete session", "content_type": ["sessions", "session"], "codename": "delete_session"}}, {"model": "auth.permission", "pk": 24, "fields": {"name": "Can view session", "content_type": ["sessions", "session"], "codename": "view_session"}}, {"model": "auth.permission", "pk": 25, "fields": {"name": "Can add contact", "content_type": ["portfolio", "contact"], "codename": "add_contact"}}, {"model": "auth.permission", "pk": 26, "fields": {"name": "Can change contact", "content_type": ["portfolio", "contact"], "codename": "change_contact"}}, {"model": "auth.permission", "pk": 27, "fields": {"name": "Can delete contact", "content_type": ["portfolio", "contact"], "codename": "delete_contact"}}, {"model": "auth.permission", "pk": 28, "fields": {"name": "Can view contact", "content_type": ["portfolio", "contact"], "codename": "view_contact"}}, {"model": "auth.permission", "pk": 29, "fields": {"name": "Can add category_post", "content_type": ["blogs", "category_post"], "codename": "add_category_post"}}, {"model": "auth.permission", "pk": 30, "fields": {"name": "Can change category_post", "content_type": ["blogs", "category_post"], "codename": "change_category_post"}}, {"model": "auth.permission", "pk": 31, "fields": {"name": "Can delete category_post", "content_type": ["blogs", "category_post"], "codename": "delete_category_post"}}, {"model": "auth.permission", "pk": 32, "fields": {"name": "Can view category_post", "content_type": ["blogs", "category_post"], "codename": "view_category_post"}}, {"model": "auth.permission", "pk": 33, "fields": {"name": "Can add post", "content_type": ["blogs", "post"], "codename": "add_post"}}, {"model": "auth.permission", "pk": 34, "fields": {"name": "Can change post", "content_type": ["blogs", "post"], "codename": "change_post"}}, {"model": "auth.permission", "pk": 35, "fields": {"name": "Can delete post", "content_type": ["blogs", "post"], "codename": "delete_post"}}, {"model": "auth.permission", "pk": 36, "fields": {"name": "Can view post", "content_type": ["blogs", "post"], "codename": "view_post"}}, {"model": "auth.permission", "pk": 37, "fields": {"name": "Can add comment", "content_type": ["blogs", "comment"], "codename": "add_comment"}}, {"model": "auth.permission", "pk": 38, "fields": {"name": "Can change comment", "content_type": ["blogs", "comment"], "codename": "change_comment"}}, {"model": "auth.permission", "pk": 39, "fields": {"name": "Can delete comment", "content_type": ["blogs", "comment"], "codename": "delete_comment"}}, {"model": "auth.permission", "pk": 40, "fields": {"name": "Can view comment", "content_type": ["blogs", "comment"], "codename": "view_comment"}}, {"model": "auth.permission", "pk": 41, "fields": {"name": "Can add category_work", "content_type": ["works", "category_work"], "codename": "add_category_work"}}, {"model": "auth.permission", "pk": 42, "fields": {"name": "Can change category_work", "content_type": ["works", "category_work"], "codename": "change_category_work"}}, {"model": "auth.permission", "pk": 43, "fields": {"name": "Can delete category_work", "content_type": ["works", "category_work"], "codename": "delete_category_work"}}, {"model": "auth.permission", "pk": 44, "fields": {"name": "Can view category_work", "content_type": ["works", "category_work"], "codename": "view_category_work"}}, {"model": "auth.permission", "pk": 45, "fields": {"name": "Can add work", "content_type": ["works", "work"], "codename": "add_work"}}, {"model": "auth.permission", "pk": 46, "fields": {"name": "Can change work", "content_type": ["works", "work"], "codename": "change_work"}}, {"model": "auth.permission", "pk": 47, "fields": {"name": "Can delete work", "content_type": ["works", "work"], "codename": "delete_work"}}, {"model": "auth.permission", "pk": 48, "fields": {"name": "Can view work", "content_type": ["works", "work"], "codename": "view_work"}}, {"model": "auth.permission", "pk": 49, "fields": {"name": "Can add attachment", "content_type": ["django_summernote", "attachment"], "codename": "add_attachment"}}, {"model": "auth.permission", "pk": 50, "fields": {"name": "Can change attachment", "content_type": ["django_summernote", "attachment"], "codename": "change_attachment"}}, {"model": "auth.permission", "pk": 51, "fields": {"name": "Can delete attachment", "content_type": ["django_summernote", "attachment"], "codename": "delete_attachment"}}, {"model": "auth.permission", "pk": 52, "fields": {"name": "Can view attachment", "content_type": ["django_summernote", "attachment"], "codename": "view_attachment"}}, {"model": "auth.permission", "pk": 53, "fields": {"name": "Can add tag", "content_type": ["taggit", "tag"], "codename": "add_tag"}}, {"model": "auth.permission", "pk": 54, "fields": {"name": "Can change tag", "content_type": ["taggit", "tag"], "codename": "change_tag"}}, {"model": "auth.permission", "pk": 55, "fields": {"name": "Can delete tag", "content_type": ["taggit", "tag"], "codename": "delete_tag"}}, {"model": "auth.permission", "pk": 56, "fields": {"name": "Can view tag", "content_type": ["taggit", "tag"], "codename": "view_tag"}}, {"model": "auth.permission", "pk": 57, "fields": {"name": "Can add tagged item", "content_type": ["taggit", "taggeditem"], "codename": "add_taggeditem"}}, {"model": "auth.permission", "pk": 58, "fields": {"name": "Can change tagged item", "content_type": ["taggit", "taggeditem"], "codename": "change_taggeditem"}}, {"model": "auth.permission", "pk": 59, "fields": {"name": "Can delete tagged item", "content_type": ["taggit", "taggeditem"], "codename": "delete_taggeditem"}}, {"model": "auth.permission", "pk": 60, "fields": {"name": "Can view tagged item", "content_type": ["taggit", "taggeditem"], "codename": "view_taggeditem"}}, {"model": "auth.permission", "pk": 61, "fields": {"name": "Can add Skill", "content_type": ["portfolio", "experience"], "codename": "add_experience"}}, {"model": "auth.permission", "pk": 62, "fields": {"name": "Can change Skill", "content_type": ["portfolio", "experience"], "codename": "change_experience"}}, {"model": "auth.permission", "pk": 63, "fields": {"name": "Can delete Skill", "content_type": ["portfolio", "experience"], "codename": "delete_experience"}}, {"model": "auth.permission", "pk": 64, "fields": {"name": "Can view Skill", "content_type": ["portfolio", "experience"], "codename": "view_experience"}}, {"model": "auth.permission", "pk": 65, "fields": {"name": "Can add Skill", "content_type": ["portfolio", "skill"], "codename": "add_skill"}}, {"model": "auth.permission", "pk": 66, "fields": {"name": "Can change Skill", "content_type": ["portfolio", "skill"], "codename": "change_skill"}}, {"model": "auth.permission", "pk": 67, "fields": {"name": "Can delete Skill", "content_type": ["portfolio", "skill"], "codename": "delete_skill"}}, {"model": "auth.permission", "pk": 68, "fields": {"name": "Can view Skill", "content_type": ["portfolio", "skill"], "codename": "view_skill"}}, {"model": "auth.permission", "pk": 69, "fields": {"name": "Can add education", "content_type": ["experiences", "education"], "codename": "add_education"}}, {"model": "auth.permission", "pk": 70, "fields": {"name": "Can change education", "content_type": ["experiences", "education"], "codename": "change_education"}}, {"model": "auth.permission", "pk": 71, "fields": {"name": "Can delete education", "content_type": ["experiences", "education"], "codename": "delete_education"}}, {"model": "auth.permission", "pk": 72, "fields": {"name": "Can view education", "content_type": ["experiences", "education"], "codename": "view_education"}}, {"model": "auth.permission", "pk": 73, "fields": {"name": "Can add employment", "content_type": ["experiences", "employment"], "codename": "add_employment"}}, {"model": "auth.permission", "pk": 74, "fields": {"name": "Can change employment", "content_type": ["experiences", "employment"], "codename": "change_employment"}}, {"model": "auth.permission", "pk": 75, "fields": {"name": "Can delete employment", "content_type": ["experiences", "employment"], "codename": "delete_employment"}}, {"model": "auth.permission", "pk": 76, "fields": {"name": "Can view employment", "content_type": ["experiences", "employment"], "codename": "view_employment"}}, {"model": "auth.user", "pk": 1, "fields": {"password": "pbkdf2_sha256$260000$oeBG0YgaetWQDf4xpllRSR$yIlMj7uusOl9JxWwIaZk9t0CQAvf0ChKrehno8xuZiE=", "last_login": "2022-11-09T05:11:20.695Z", "is_superuser": true, "username": "sagar", "first_name": "Sagar", "last_name": "Budha", "email": "sagar@sagar.com", "is_staff": true, "is_active": true, "date_joined": "2021-05-26T01:48:47Z", "groups": [], "user_permissions": []}}, {"model": "auth.user", "pk": 2, "fields": {"password": "pbkdf2_sha256$260000$T62gj4lDagbAPMIVqdbwlN$N35zdYKZr4nPzs60zikatpKh/otzusVevT+U/J37Occ=", "last_login": "2022-07-19T12:19:51.027Z", "is_superuser": true, "username": "adminsagar", "first_name": "", "last_name": "", "email": "mail@budhathokisagar.com.np", "is_staff": true, "is_active": true, "date_joined": "2022-07-19T12:19:40.279Z", "groups": [], "user_permissions": []}}, {"model": "blogs.post", "pk": 1, "fields": {"title": "AI Chatbot", "slug": "ai-chatbot", "author": ["sagar"], "updated_on": "2022-11-19T23:42:41.811Z", "short_desciption": "AI powered chatbot with RASA stack", "image": "media/images/chatbot3_wbxpkl_uzkai6", "content": "![](https://res.cloudinary.com/sbmagar-media-storage/image/upload/v1/media/django-summernote/2021-08-02/e1361e17-1d1b-43e3-bbda-1448cd9a5a1d_kxoj01)  \r\n\r\n  \r\n\r\nDemo version of personal\\_bot: [https://sbmagar.github.io](https://sbmagar.github.io) ....\r\n\r\nsource code : [https://github.com/SBMagar/personal\\_chatbot](https://github.com/SBMagar/personal_chatbot)\r\n\r\nProduction phase official chatbot on VolgAI website([https://volgai.com](https://www.blogger.com/blog/post/edit/2875741694909600015/7287179243067575496#))\r\n\r\n  \r\n\r\nBot is developed using Python RASA-Stack(Docker, docker-compose, supervisord, Nginx, RabbitMQ, Redis, PostgreSQL etc.)", "publish": "2022-01-25T20:42:30Z", "created_on": "2021-05-26T09:11:24.666Z", "status": 1, "visit_num": 656, "keywords": "Python", "categories": [1]}}, {"model": "blogs.post", "pk": 2, "fields": {"title": "Nepal - Covid-19 Prediction models using different ML algorithms", "slug": "nepal-covid-19-prediction-models-using-different-ml-algorithms", "author": ["sagar"], "updated_on": "2022-11-19T05:45:27.442Z", "short_desciption": "Covid-19 Prediction models using different ML algorithms", "image": "media/images/outputsigmoidal_ohg2f2", "content": "I am using a sigmoidal function to fit the historical data of Covid-19 and predict or forecast. And also use LinearRegression and RandomForestRegressor to predict. I thought of a sigmoidal function first because China's data resembled a sigmoidal shape. Therefore, I try to fit sigmoid functions onto Nepal also.\r\n\r\n**Step-1:Load dataset from s3 (download from [https://covid.ourworldindata.org/data/owid-covid-data.csv](https://covid.ourworldindata.org/data/owid-covid-data.csv))**\r\n\r\nimport pandas as pd\r\n\r\nimport numpy as np\r\n\r\nimport matplotlib.pyplot as plt\r\n\r\nplt.style.use('fivethirtyeight')\r\n\r\n  \r\n\r\ndf1=pd.read\\_csv('s3://sagemaker-studio-im065hy7nj/owid-covid-data.csv')\r\n\r\n  \r\n\r\n#df1.head(5)\r\n\r\ndf1.columns\r\n\r\n**Step-2: Subsetting only those rows that have \"NPL\" in the \"location\" column and plot y-axis total\\_cases over x-axis as day-count.**\r\n\r\n  \r\n\r\nNepal\\_df = df1\\[df1\\['location'\\]=='Nepal'\\].groupby('date')\\[\\['total\\_cases','total\\_deaths'\\]\\].sum()\r\n\r\nNepal\\_df\\['day\\_count'\\] = list(range(1,len(Nepal\\_df)+1))\r\n\r\nydata = Nepal\\_df.total\\_cases\r\n\r\nxdata = Nepal\\_df.day\\_count\r\n\r\nNepal\\_df\\['rate'\\] = (Nepal\\_df.total\\_cases-Nepal\\_df.total\\_cases.shift(1))/Nepal\\_df.total\\_cases\r\n\r\nNepal\\_df\\['increase'\\] = (Nepal\\_df.total\\_cases-Nepal\\_df.total\\_cases.shift(1))\r\n\r\n\\# Nepal\\_df = Nepal\\_df\\[Nepal\\_df.total\\_cases>100\\]\r\n\r\n  \r\n\r\nplt.plot(xdata, ydata, 'o')\r\n\r\nplt.title(\"Nepal\")\r\n\r\nplt.ylabel(\"Population Infected\")\r\n\r\nplt.xlabel(\"Days\")\r\n\r\nplt.show()\r\n\r\n**Output:**  \r\n\r\n  \r\n\r\n[![](https://lh3.googleusercontent.com/-V9b4x75_Fz8/YH0aGXkia4I/AAAAAAAAKgU/D0m8rtflFxcb30Z5SMRvw3oje_pwDsOzwCNcBGAsYHQ/image.png)](https://www.blogger.com/blog/post/edit/2875741694909600015/6667143551291784996#)\r\n\r\n  \r\n  \r\n\r\n  \r\n\r\n  \r\n\r\n**Step-3: Sigmoidal Function:**\r\n\r\n**\r\n\r\nfrom scipy.optimize import curve\\_fit\r\n\r\nimport pylab\r\n\r\n  \r\n\r\ndef sigmoid(x,c,a,b):\r\n\r\ny = c\\*1 / (1 + np.exp(-a\\*(x-b)))\r\n\r\nreturn y\r\n\r\n  \r\n\r\nxdata = np.array(\\[1, 2, 3,4, 5, 6, 7\\])\r\n\r\nydata = np.array(\\[0, 0, 13, 35, 75, 89, 91\\])\r\n\r\n  \r\n\r\npopt, pcov = curve\\_fit(sigmoid, xdata, ydata, method='dogbox',bounds=(\\[0.,0., 0.\\],\\[100,2, 10.\\]))\r\n\r\nprint(popt)\r\n\r\n  \r\n\r\nx = np.linspace(\\-1, 10, 50)\r\n\r\ny = sigmoid(x, \\*popt)\r\n\r\n  \r\n\r\npylab.plot(xdata, ydata, 'o', label='data')\r\n\r\npylab.plot(x,y, label='fit')\r\n\r\npylab.ylim(\\-0.05, 105)\r\n\r\npylab.legend(loc='best')\r\n\r\npylab.show()\r\n\r\n\r\n\r\n**\r\n\r\n  \r\n\r\n  \r\n\r\n  \r\n\r\n[![](https://lh3.googleusercontent.com/-WLxbj5ze2vA/YH00h8WPXEI/AAAAAAAAKgg/lFqGf2x2XGA0AMQr8BbY4du1eHOXPrMjgCNcBGAsYHQ/image.png)](https://www.blogger.com/blog/post/edit/2875741694909600015/6667143551291784996#)\r\n\r\n  \r\n\r\n  \r\n\r\n  \r\n\r\nSigmoid function, Here is a snap of how I learnt to fit Sigmoid Function - y = c/(1+np.exp(-a\\*(x-b))) and 3 coefficients \\[c, a, b\\]:\r\n\r\n*   c - the maximum value (eventual maximum infected people, the sigmoid scales to this value eventually)\r\n*   a - the sigmoidal shape (how the infection progress. The smaller, the softer the sigmoidal shape is)\r\n*   b - the point where the sigmoid start to flatten from steepening (the midpoint of sigmoid, when the rate of increase start to slow down)\r\n\r\n  \r\n\r\n  \r\n\r\n**Step-4: Since our dataset doesn't have a recovered cases column so I am gonna import and read the next dataset**\r\n\r\ndf2 = pd.read\\_csv('s3://sagemaker-studio-im065hy7nj/time\\_series\\_covid19\\_recovered\\_global.csv')\r\n\r\n  \r\n\r\n\\# Extract list of values of 'recovered' column and insert that column to our first data-subset with proper arrangement.\r\n\r\n\\# Since few pairs of row doesn't exist in column of new dataset, so we gonna manually add values referencing other sites.\r\n\r\nlist(df2.iloc\\[172, 4:\\])\r\n\r\ninput\\_values = \\[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 4, 4, 4, 7, 10, 11, 12, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 22, 22, 31, 31, 31, 33, 33, 35, 35, 36, 36, 36, 36, 37, 45, 49, 70, 70, 87, 112, 155, 183, 187, 206, 219, 220, 221, 266, 278, 290, 333, 365, 467, 488, 584, 674, 861, 877, 913, 974, 1041, 1158, 1167, 1186, 1402, 1578, 1772, 2148, 2224, 2338, 2650, 2698, 2834, 3013, 3134, 3194, 4656, 5320, 6143, 6415, 6547, 6811, 7499, 7752, 7891, 8011, 8442, 8589, 10294, 10328, 11025, 11249, 11534, 11637, 11695, 11868, 12477, 12684, 12840, 12947, 13053, 13128, 13754, 13875, 14021, 14248, 14399, 14492, 14603, 14961, 15026, 15156, 15389, 15814, 16313, 16353, 16493, 16664, 16728, 16837, 17077, 17201, 17335, 17495, 17580, 17700, 17964, 18214, 18350, 18631, 18806, 19119, 19504, 20073, 20242, 20555, 20822, 21410, 22178, 23290, 24207, 25561, 27127, 28941, 30677, 32964, 33882, 35700, 36672, 37524, 38697, 39576, 40638, 41706, 42949, 43820, 45267, 46233, 47238, 48061, 49954, 50411, 51866, 53013, 53898, 54640, 55371, 56428, 57389, 60696, 62740, 64069, 65202, 67542, 68668, 71343, 73023, 74252, 75804, 77277, 78780, 80954\\]\r\n\r\nlen(input\\_values)\r\n\r\n**step-5: Creating new subset with required columns and rows only:**\r\n\r\nin\\_df1 = df1\\[df1\\['location'\\]=='Nepal'\\].groupby('date')\\[\\['total\\_cases', 'new\\_cases', 'total\\_deaths', 'new\\_deaths', 'total\\_tests'\\]\\].sum().reset\\_index(False)\r\n\r\nin\\_df1\\['recovered'\\]= np.array(input\\_values).copy()\r\n\r\nin\\_df1\\['Active'\\]=in\\_df1\\['total\\_cases'\\]-in\\_df1\\['new\\_deaths'\\]-in\\_df1\\['recovered'\\]\r\n\r\n\\# in\\_df1 = in\\_df1\\[in\\_df1.Active>=20\\]\r\n\r\n  \r\n\r\nin\\_df1.head(10)\r\n\r\n  \r\n\r\nin\\_df1.isnull().sum()\r\n\r\n  \r\n\r\n**Step-6: Sigmoidal fitting**\r\n\r\nin\\_df1\\['day\\_count'\\] = list(range(1, len(in\\_df1)+1))\r\n\r\nin\\_df1\\['increase'\\] = (in\\_df1.total\\_cases-in\\_df1.total\\_cases.shift(1))\r\n\r\nin\\_df1\\['rate'\\] = (in\\_df1.total\\_cases-in\\_df1.total\\_cases.shift(1))/in\\_df1.total\\_cases\r\n\r\n  \r\n  \r\n\r\ndef sigmoid(x,c,a,b):\r\n\r\ny = c\\*1 / (1 + np.exp(-a\\*(x-b)))\r\n\r\nreturn y\r\n\r\n  \r\n\r\nxdata = np.array(list(in\\_df1.day\\_count)\\[::2\\])\r\n\r\nydata = np.array(list(in\\_df1.total\\_cases)\\[::2\\])\r\n\r\n  \r\n\r\n\\# population=29136808\r\n\r\n\\# popt, pcov = curve\\_fit(sigmoid, xdata, ydata, method='dogbox',bounds=(\\[0., 0., 0.\\], \\[population, 6, 180.\\]))\r\n\r\n\\# print(popt)\r\n\r\n**Step-7: Prediction Using Manual sigmoidal fitting:**\r\n======================================================\r\n\r\nimport pylab\r\n\r\n  \r\n\r\nest\\_a = 145000\r\n\r\nest\\_b = 0.04\r\n\r\nest\\_c = 270\r\n\r\nx = np.linspace(\\-1, Nepal\\_df.day\\_count.max()+50, 50)\r\n\r\ny = sigmoid(x,est\\_a,est\\_b,est\\_c)\r\n\r\npylab.plot(xdata, ydata, 'o', label='data')\r\n\r\npylab.plot(x,y, label='fit',alpha = 0.8)\r\n\r\npylab.ylim(\\-0.05, est\\_a\\*1.05)\r\n\r\npylab.xlim(\\-0.05, est\\_c\\*2.05)\r\n\r\npylab.legend(loc='best')\r\n\r\nplt.xlabel('days from day 1')\r\n\r\nplt.ylabel('Infection Cases')\r\n\r\nplt.title('Nepal')\r\n\r\npylab.show()\r\n\r\n  \r\n\r\nprint('model start date:',Nepal\\_df\\[Nepal\\_df.day\\_count==1\\].index\\[0\\])\r\n\r\nprint('model start infection:',int(Nepal\\_df\\[Nepal\\_df.day\\_count==1\\].total\\_cases\\[0\\]))\r\n\r\nprint('model fitted max infection at:',int(est\\_a))\r\n\r\nprint('model sigmoidal coefficient is:',round(est\\_b,2))\r\n\r\nprint('model curve stop steepening, start flattening by day:',int(est\\_c))\r\n\r\nprint('which is date:', Nepal\\_df\\[Nepal\\_df.day\\_count==int(est\\_c)\\].index\\[0\\])\r\n\r\nprint('model curve flattens by day:',int(est\\_c)\\*2)\r\n\r\n  \r\n\r\ndisplay(Nepal\\_df.head(3))\r\n\r\ndisplay(Nepal\\_df.tail(3))\r\n\r\n  \r\n\r\n[![](https://lh3.googleusercontent.com/-tb-5R0G_a7M/YH054Az09tI/AAAAAAAAKgo/JGPhxEMYI44z04MDHOVvvk5MNZd-WskmgCNcBGAsYHQ/image.png)](https://www.blogger.com/blog/post/edit/2875741694909600015/6667143551291784996#)\r\n\r\n  \r\n\r\n[![](https://lh3.googleusercontent.com/-_saEyuK_jT4/YH058QSuinI/AAAAAAAAKgs/MQZDDXGvLsYn65i3XdTYA5b_N-x2B1opgCNcBGAsYHQ/w320-h299/image.png)](https://www.blogger.com/blog/post/edit/2875741694909600015/6667143551291784996#)\r\n\r\n  \r\n\r\n**Nepal,**\r\n\r\n*   The b coefficient is 270, which means that the model starts to flatten 270 days, after the 25th of September, and really flatten significantly after 540 days.\r\n    \r\n*   The c coefficient is 145000, which is the predicted amount of infected people.\r\n    \r\n*   The coefficient is 0.04 is smaller than China's 0.22, which means the sigmoid is even softer in China. This means that Nepal will take even longer than China to fight Covid-19.\r\n    \r\n\r\n  \r\n\r\nFrom this, its seen that in Nepal if the graph goes like that:\r\n\r\nmax Active case: 145000,\r\n\r\ncurve stop steepening, start flattening by day: 270,\r\n\r\nwhich is: 2020-09-25,\r\n\r\nthe curve flattens by day: 540\r\n\r\n  \r\n\r\n\r\n\r\n===========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================\r\n\r\n**Linear Regression and Random Forest for prediction:**\r\n=======================================================\r\n\r\n**For this part, please go through sourcecode with explanations:**  [https://colab.research.google.com/drive/1uKgB3L-7C5OtuhEdr0W1g2F-U3yV84vA#scrollTo=mYLbmyLGAFE\\_](https://colab.research.google.com/drive/1uKgB3L-7C5OtuhEdr0W1g2F-U3yV84vA#scrollTo=mYLbmyLGAFE_)", "publish": "2022-01-25T20:42:30Z", "created_on": "2021-05-26T12:44:36.585Z", "status": 1, "visit_num": 715, "keywords": "Python", "categories": [1]}}, {"model": "blogs.post", "pk": 3, "fields": {"title": "Simple Amazon Lex Weather Chatbot", "slug": "simple-amazon-lex-weather-chatbot", "author": ["sagar"], "updated_on": "2022-11-20T01:18:37.417Z", "short_desciption": "A weather forecast and information chatbot, Created with AWS Lex and AWS lambda", "image": "media/images/SNAPSHOTS-2_h5segh", "content": "amazon-lex-weather bot\r\n======================\r\n\r\n[![](https://1.bp.blogspot.com/-Unzy1s8Z96o/YHyCmbsDTgI/AAAAAAAAKgA/jMI3kvUsLf0Z5rEswFYsga8jZml6mZI5gCNcBGAsYHQ/s320/awslex.PNG)](https://www.blogger.com/blog/post/edit/2875741694909600015/5900299110462152866#)\r\n\r\n  \r\n\r\n\r\n\r\n===========================================================================================================================================================================================================================\r\n\r\n\"\"\" A weather forecast and information chatbot, Created with AWS Lex and AWS lambda\"\"\"\r\n\r\n[](https://www.blogger.com/blog/post/edit/2875741694909600015/5900299110462152866#)_`About Lex BOT`_\r\n----------------------------------------------------------------------------------------------------\r\n\r\nAWS Lex projects have three objects:\r\n\r\n    Bot\r\n    Intents\r\n    Slots\r\n    \r\n\r\n                   \r\n\r\nThe intent is what the user asks for, and will be executed whenever the intent is selected by the NLU module and all required slots are filled up. Intents are defined by a set of sample sentences, which are used to train the model and slots. The sentences should be defined in such a way that they contain slots.\r\n\r\nFor example, if we have a slot type City, then one of our sentences could be Show me the weather in {city}. Now, the underlying ML uses this combination of sentences and slot types to train the model.\r\n\r\nSlots are used to fetch the parameters required by the intent to fulfill the user request. There are two types of slots: the predefined and the custom ones. Amazon Lex supports built-in slot types from the Alexa Skills Kit.\r\n\r\n[](https://www.blogger.com/blog/post/edit/2875741694909600015/5900299110462152866#)`My Demo App`\r\n------------------------------------------------------------------------------------------------\r\n\r\n`   `\r\n\r\n[![](https://1.bp.blogspot.com/-4YkJVIqbs7o/YHyCuFaIsRI/AAAAAAAAKgI/jWrKEo2pkYY-5yF0SKeWBEL1Cc1GdxBJQCNcBGAsYHQ/s320/SNAPSHOTS-5%2528City%2529.PNG)](https://www.blogger.com/blog/post/edit/2875741694909600015/5900299110462152866#)\r\n\r\n  \r\n\r\nThe demo application I wrote is in Python and made use of Lambda for the state management, conditions, decision trees, and the like. Lex expects the Lambda function to receive a JSON payload. Subsequently, the Lambda function needs to return a JSON payload to Lex. The connection can be tested via the text console and the JSON payload is visible during testing.\r\n\r\nI have created two intents: 1) WeatherNow, 2) WeatherForecast. One for the current weather conditions of different cities input by the user, and the second one is for forecast data of weather.\r\n\r\nIn this demo, I used OpenWeatherMap's API for weather data. Since only Lattitude and Longitude values are supported for forecasting weather(free members), I have used latitude and longitude values as slots in lex for forecasting weather, While City name or location name is used for current(today's) weather pieces of information.\r\n\r\nI used aws' built-in confirmation prompt features. Single \"Lambda function\" source code is used for fulfillment response plus initialization and validation of one of the intents.\r\n\r\nFor slots: the city is defined with a built-in 'AMAZON.AT\\_CITIES' slot type to match the city the user is asking about, and both lat and long are defined with built-in 'AMAZON.NUMBER'.\r\n\r\n  \r\n\r\nsourcecode: [https://github.com/SBMagar/amazon-lex-weatherbot](https://www.blogger.com/blog/post/edit/2875741694909600015/5900299110462152866#)", "publish": "2022-01-25T20:42:30Z", "created_on": "2021-05-26T12:51:56.622Z", "status": 1, "visit_num": 884, "keywords": "Python", "categories": [1]}}, {"model": "blogs.post", "pk": 4, "fields": {"title": "Django, Postgres, Gunicorn, Nginx with Docker (Part-1)", "slug": "django-postgres-gunicorn-nginx-docker", "author": ["sagar"], "updated_on": "2022-11-21T18:50:10.427Z", "short_desciption": "Configuring Django to run on Docker with Postgres", "image": "media/images/Untitled_design_4_kksqpo", "content": "﻿**Prerequisites**\r\n\r\n﻿First, ensure the following is installed on you machine:\r\n\r\n*   [Python](https://www.python.org/) 3.7 or higher(I've used python 3.8.9)\r\n*   Python [pip](https://pypi.org/project/pip/)\r\n*   [Git](https://git-scm.com/) and a [GitHub](https://github.com/) account\r\n*   [Docker](https://www.docker.com/) and [docker-compose](https://docs.docker.com/compose/install/)\r\n\r\nLet's jump directly to dockerization of django web application. I'm sure you have django project set-up on your system. \r\n\r\n  \r\n\r\nDocker\r\n\r\n﻿After installation of docker, add a _Dockerfile_ to the root directory of you project:\r\n\r\n  \r\n\r\n  \r\n\r\n    FROM python:3.8.9-alpine\r\n    \r\n    WORKDIR /app\r\n    \r\n    ENV PYTHONDONTWRITEBYTECODE 1\r\n    ENV PYTHONNUNBUFFERED 1\r\n    \r\n    RUN pip install --upgrade pip\r\n    COPY ./requirements.txt .\r\n    \r\n    RUN pip install -r requirements.txt\r\n    \r\n    COPY . .\r\n    \r\n\r\n  \r\n\r\nHere, we used alpine-based docker image for python 3.8.9. Then we set two environmental variables:\r\n\r\n1.  PYTHONDONTWRITEBYTECODE (which prevents writing pyc files)\r\n2.  PYTHONUNBUFFERED (which prevents buffering stdout and stderr)\r\n\r\nAnd, we updated pip version and copied _requirements.txt_ file to working directory, and installed requirements. After that we finally codpied our project to working directory(/app).\r\n\r\n  \r\n\r\n﻿Now, create a docker-compose.yml file to the project root and add services:\r\n\r\n  \r\n\r\n    version: '3.5'\r\n    \r\n    services:\r\n        app:\r\n            build: .\r\n            command: python manage.py runserver 0.0.0.0:8000\r\n            volumes:\r\n                - static_data:/vol/web\r\n            ports:\r\n                - \"8000:8000\"\r\n            restart: always\r\n            env_file:\r\n                - ./.env\r\n\r\n  \r\n\r\n﻿Create .env file at the root (same directory containing docker-compose.yml) and edit as:\r\n\r\n    DEBUG=1\r\n    SECRET_KEY=foo\r\n    DJANGO_ALLOWED_HOSTS=localhost 127.0.0.1 [::]\r\n\r\n﻿Update DEBUG, ALLOWED\\_HOSTS variables in _settings.py_:\r\n\r\n  \r\n\r\n    DEBUG = int(os.environ.get(\"DEBUG\", default=0))\r\n    \r\n    # 'DJANGO_ALLOWED_HOSTS' should be a single string of hosts with a space between each.\r\n    # For example: 'DJANGO_ALLOWED_HOSTS=localhost 127.0.0.1 [::1]'\r\n    ALLOWED_HOSTS = os.environ.get(\"DJANGO_ALLOWED_HOSTS\").split(\" \")\r\n\r\nIn docker-compose file, _build: ._ means it will build image from the root Dockerfile we have created before.\r\n\r\nNow, build the image:\r\n\r\n    $ docker-compose build \r\n\r\nUse sudo if needed.\r\n\r\nRun the container once image is built:\r\n\r\n    $ docker-compose up -d \r\n\r\n_\\-d_ is used to run process in background.\r\n\r\nIf it this doesn't work check errors  with **_docker-compose logs -f_** command.\r\n\r\n  \r\n\r\n﻿**Postgres**\r\n\r\n﻿Add new service to the _docker-compose.yml_ file, and update django database settings, with [Psycopg2](http://initd.org/psycopg/).lets add new service named as app-db:\r\n\r\n    version: '3.5'\r\n    \r\n    services:\r\n        app:\r\n            build: .\r\n            command: python manage.py runserver 0.0.0.0:8000\r\n            volumes:\r\n                - static_data:/vol/web\r\n            ports:\r\n                - \"8000:8000\"\r\n            restart: always\r\n            env_file:\r\n                - ./.env\r\n            depends_on:\r\n                - app-db\r\n    \r\n        app-db:\r\n            image: postgres:12-alpine\r\n            ports:\r\n                - \"5432:5432\"\r\n            restart: always\r\n            volumes:\r\n                - postgres_data:/var/lib/postgresql/data:rw\r\n            env_file:\r\n                - .env\r\n    # you can also use environmental variables directly as following:\r\n    #(remember variables for postgres should be named exactly as given below)\r\n    #        environment:\r\n    #            - POSTGRES_HOST_AUTH_METHOD=trust\r\n    #            - POSTGRES_USER:sagar\r\n    #            - POSTGRES_PASSWORD:********\r\n    #            - POSTGRES_DB:portfolio_db\r\n    #            - TZ:Asia/Kathmandu\r\n\r\n    \r\n\r\nWe will just use the official Postgres docker image and postgres\\_data is the persistent data volume within docker. It should suffice.\r\n\r\n  \r\n\r\n    DEBUG=1\r\n    DJANGO_ALLOWED_HOSTS=localhost 127.0.0.1 [::1]\r\n    POSTGRES_HOST_AUTH_METHOD=trust\r\n    POSTGRES_USER=sagar\r\n    POSTGRES_PASSWORD=********\r\n    POSTGRES_DB=portfolio_db\r\n    POSTGRES_HOST=app-db\r\n    POSTGRES_PORT=5432\r\n\r\n  \r\n\r\nUpdate the DATABASES dict in settings.py:\r\n\r\n    DATABASES = {\r\n        'default': {\r\n            'ENGINE': os.environ.get(\"DB_ENGINE\", \"django.db.backends.sqlite3\"),\r\n            'NAME': os.environ.get(\"POSTGRES_DB\", os.path.join(BASE_DIR, \"db.sqlite3\")),\r\n            'USER': os.environ.get(\"POSTGRES_USER\", \"default_user\"),\r\n            'PASSWORD': os.environ.get(\"POSTGRES_PASSWORD\", \"default_password\"),\r\n            'HOST': os.environ.get(\"POSTGRES_HOST\", \"localhost\"),\r\n            'PORT': os.environ.get(\"POSTGRES_PORT\", \"5432\"),\r\n    \r\n        }\r\n    }\r\n\r\nHere, the database is configured based on the environment variables that we just defined. Take note of the default values. Update the Dockerfile to install the appropriate packages required for Psycopg2:\r\n\r\n    From python:3.8.9-alpine\r\n    \r\n    WORKDIR /app\r\n    \r\n    PYTHONDONTWRITEBYTECODE 1\r\n    ENV PYTHONNUNBUFFERED 1\r\n    \r\n    #psycopg2 dependencies installation\r\n    RUN apk update\r\n    RUN apk add postgresql-dev gcc python3-dev musl-dev libc-dev linux-headers\r\n    \r\n    RUN pip install --upgrade pip\r\n    COPY ./requirements.txt .\r\n    \r\n    RUN pip install -r requirements.txt\r\n    \r\n    COPY . .\r\n\r\n  \r\n\r\nAdd Psycopg2 to _requirements.txt_. Make sure everytime you install packages, they are added to requirements.txt file. (_pip freeze > requirements.txt_)\r\n\r\nBuild the new image with two services:\r\n\r\n    $ docker-compose up -d --build\r\n\r\n  \r\n\r\nThen run the migrations:\r\n\r\n    $ docker-compose exec app python manage.py migrate --noinput\r\n\r\n Operations to perform:\r\n      Apply all migrations: admin, auth, blogs, contenttypes, django_summernote, portfolio, sessions, works\r\n    Running migrations:\r\n      Applying contenttypes.0001_initial... OK\r\n      Applying auth.0001_initial... OK\r\n      Applying admin.0001_initial... OK\r\n      Applying admin.0002_logentry_remove_auto_add... OK\r\n      Applying admin.0003_logentry_add_action_flag_choices... OK\r\n      Applying contenttypes.0002_remove_content_type_name... OK\r\n      Applying auth.0002_alter_permission_name_max_length... OK\r\n      Applying auth.0003_alter_user_email_max_length... OK\r\n      Applying auth.0004_alter_user_username_opts... OK\r\n      Applying auth.0005_alter_user_last_login_null... OK\r\n      Applying auth.0006_require_contenttypes_0002... OK\r\n      Applying auth.0007_alter_validators_add_error_messages... OK\r\n      Applying auth.0008_alter_user_username_max_length... OK\r\n      Applying auth.0009_alter_user_last_name_max_length... OK\r\n      Applying auth.0010_alter_group_name_max_length... OK\r\n      Applying auth.0011_update_proxy_permissions... OK\r\n      Applying blogs.0001_initial... OK\r\n      Applying django_summernote.0001_initial... OK\r\n      Applying django_summernote.0002_update-help_text... OK\r\n      Applying portfolio.0001_initial... OK\r\n      Applying sessions.0001_initial... OK\r\n      Applying works.0001_initial... OK\r\n      Applying works.0002_auto_20200325_1330... OK\r\n      Applying works.0003_auto_20200325_1411... OK\r\n      Applying works.0004_auto_20200325_1413... OK\r\n      Applying works.0005_auto_20200325_1417... OK\r\n      Applying works.0006_remove_work_image... OK\r\n      Applying works.0007_work_image... OK\r\n\r\n  \r\n\r\nIf any error, run **_docker-compose down -v_** to remove the volumes along with the containers. Then re-build and run migrations.\r\n\r\nEnsure datavase tables are created:\r\n\r\n    $ docker-compose exec app-db psql --username=user --dbname=portfolio_db\r\n\r\n$ sudo docker-compose exec app-db psql --username=sagar --dbname=portfolio_db\r\n    psql (12.7)\r\n    Type \"help\" for help.\r\n    \r\n    portfolio_db=# \\c portfolio_db\r\n    You are now connected to database \"portfolio_db\" as user \"sagar\".\r\n    portfolio_db=# \\l\r\n                                   List of databases\r\n         Name     | Owner | Encoding |  Collate   |   Ctype    | Access privileges \r\n    --------------+-------+----------+------------+------------+-------------------\r\n     portfolio_db | sagar | UTF8     | en_US.utf8 | en_US.utf8 | \r\n     postgres     | sagar | UTF8     | en_US.utf8 | en_US.utf8 | \r\n     template0    | sagar | UTF8     | en_US.utf8 | en_US.utf8 | =c/sagar         +\r\n                  |       |          |            |            | sagar=CTc/sagar\r\n     template1    | sagar | UTF8     | en_US.utf8 | en_US.utf8 | =c/sagar         +\r\n                  |       |          |            |            | sagar=CTc/sagar\r\n    (4 rows)\r\n    \r\n    portfolio_db=# \\dt\r\n                       List of relations\r\n     Schema |             Name             | Type  | Owner \r\n    --------+------------------------------+-------+-------\r\n     public | auth_group                   | table | sagar\r\n     public | auth_group_permissions       | table | sagar\r\n     public | auth_permission              | table | sagar\r\n     public | auth_user                    | table | sagar\r\n     public | auth_user_groups             | table | sagar\r\n     public | auth_user_user_permissions   | table | sagar\r\n     public | blogs_category_post          | table | sagar\r\n     public | blogs_comment                | table | sagar\r\n     public | blogs_post                   | table | sagar\r\n     public | blogs_post_categories        | table | sagar\r\n     public | django_admin_log             | table | sagar\r\n     public | django_content_type          | table | sagar\r\n     public | django_migrations            | table | sagar\r\n     public | django_session               | table | sagar\r\n     public | django_summernote_attachment | table | sagar\r\n     public | portfolio_contact            | table | sagar\r\n     public | works_category_work          | table | sagar\r\n     public | works_work                   | table | sagar\r\n     public | works_work_categories        | table | sagar\r\n    (19 rows)\r\n    \r\n    portfolio_db=# \r\nNow add entrypoint.sh script inside scripts directory:\r\n\r\n    #!/bin/sh\r\n    \r\n    if [ \"$DATABASE\" = \"postgres\" ]\r\n    then\r\n        echo \"Waiting for postgres...\"\r\n    \r\n        while ! nc -z \"$POSTGRES_HOST\" \"$POSTGRES_PORT\"; do\r\n          sleep 0.1\r\n        done\r\n    \r\n        echo \"PostgreSQL started\"\r\n    fi\r\n    \r\n    # It's okay to run following two, flush and migrate commands on development mode(when debug mode is on) but not recommended\r\n    # for production:\r\n    \r\n    # python manage.py flush --no-input\r\n    # python manage.py migrate\r\n    \r\n    \r\n    exec \"$@\"\r\n\r\nUpdate Dockerfile with file permissions, and also add DATABASE variable to .env file.\r\n\r\n    From python:3.8.9-alpine\r\n    \r\n    WORKDIR /app\r\n    \r\n    PYTHONDONTWRITEBYTECODE 1\r\n    ENV PYTHONNUNBUFFERED 1\r\n    \r\n    #psycopg2 dependencies installation\r\n    RUN apk update\r\n    RUN apk add postgresql-dev gcc python3-dev musl-dev libc-dev linux-headers\r\n    \r\n    RUN pip install --upgrade pip\r\n    COPY ./requirements.txt .\r\n    \r\n    RUN pip install -r requirements.txt\r\n    \r\n    COPY . .\r\n    COPY ./scripts /scripts\r\n    \r\n    RUN chmod +x /scripts/*\r\n    \r\n    RUN mkdir -p /vol/web/media\r\n    RUN mkdir -p /vol/web/static\r\n    \r\n    RUN chmod -R 755 /vol/web\r\n    \r\n    ENTRYPOINT [\"/scripts/entrypoint.sh\"]\r\n\r\n  \r\n\r\nEdit .env file:\r\n\r\n    DEBUG=1\r\n    DJANGO_ALLOWED_HOSTS=localhost 127.0.0.1 [::1]\r\n    POSTGRES_HOST_AUTH_METHOD=trust\r\n    POSTGRES_USER=user\r\n    POSTGRES_PASSWORD=password\r\n    POSTGRES_DB=portfolio_db\r\n    POSTGRES_HOST=app-db #from docker-compose\r\n    POSTGRES_PORT=5432\r\n    DATABASE=postgres\r\n\r\nNow, re-build, run and try http://localhost:8000/\r\n\r\nNext: [Django, Postgres, Gunicorn, Nginx with Docker (Part-2)](https://budhathokisagar.com.np/blogs/5/)", "publish": "2022-01-25T20:42:30Z", "created_on": "2021-06-03T23:34:58.152Z", "status": 1, "visit_num": 1284, "keywords": "Python", "categories": [2]}}, {"model": "blogs.post", "pk": 5, "fields": {"title": "Django, Postgres, Gunicorn, Nginx with Docker (Part-2)", "slug": "django-postgres-gunicorn-nginx-docker-part-2", "author": ["sagar"], "updated_on": "2022-11-19T05:55:05.537Z", "short_desciption": "Configuring Django to run on Docker with Postgres, Nginx, and Gunicorn", "image": "media/images/Untitled_design_4_itbhhm", "content": "﻿Gunicorn\r\n\r\n﻿Now, install Gunicorn. It's production grade WSGI server.\r\n\r\nFor now, since we want to use default django's built-in server, create production compose file:\r\n\r\n  \r\n\r\n    version: '3.5'\r\n    \r\n    services:\r\n        app:\r\n            build:\r\n                context: .\r\n            command: gunicorn personal.wsgi:application --bind 0.0.0.0:8000\r\n            volumes:\r\n                - static_data:/vol/static\r\n            ports:\r\n                - \"8000:8000\"\r\n            restart: always\r\n            env_file:\r\n                - .env.prod\r\n            depends_on:\r\n                - app-db\r\n    \r\n        app-db:\r\n            image: postgres:12-alpine\r\n            ports:\r\n                - \"5432:5432\"\r\n            restart: always\r\n            volumes:\r\n                - postgres_data:/var/lib/postgresql/data:rw\r\n            env_file:\r\n                - .env.prod\r\n    volumes:\r\n        static_data:\r\n        postgres_data:\r\n    \r\n\r\n  \r\n\r\nHere, we're using commang gunicorn instead of django server command. we can static\\_data volume as it's not needed in production. For now, let's create .env.prod file for environemental variables:\r\n\r\n  \r\n\r\n    DEBUG=0\r\n    DJANGO_ALLOWED_HOSTS=localhost 127.0.0.1 [::1]\r\n    DB_ENGINE=django.db.backends.postgresql_psycopg2\r\n    POSTGRES_HOST_AUTH_METHOD=trust\r\n    POSTGRES_USER=sagar\r\n    POSTGRES_PASSWORD=********\r\n    POSTGRES_DB=portfolio_db_prod\r\n    POSTGRES_HOST=app-db\r\n    POSTGRES_PORT=5432\r\n    \r\n\r\n  \r\n\r\nAdd both files to _.gitignore_ file if you want to keep them out from version control. Now, down all containers with -v flag, -v flag removes associated volumes:\r\n\r\n    $ docker-compose down -v\r\n\r\nThen, re-build images and run the containers:\r\n\r\n    $ docker-compose -f docker-compose.prod.yml up --build\r\n\r\nRun with -d flag if you wan't to run services in background. If any error when running, check errors with command:\r\n\r\n    $ docker-compose -f docker-compose.prod.yml logs -f\r\n\r\nWow, let's create production Dockerfile as _Dockerfile.prod_ with production _entrypoint.prod.sh_ file inside scripts directory of the root. _entrypoint.prod.sh_ script file:\r\n\r\n  \r\n\r\n    #!/bin/sh\r\n    \r\n    if [ \"$DATABASE\" = \"postgres\" ]\r\n    then\r\n        echo \"Waiting for postgres...\"\r\n    \r\n        while ! nc -z \"$POSTGRES_HOST\" \"$POSTGRES_PORT\"; do\r\n          sleep 0.1\r\n        done\r\n    \r\n        echo \"PostgreSQL started\"\r\n    fi\r\n    \r\n    exec \"$@\"\r\n    \r\n\r\n  \r\n\r\n_Dockerfile.prod_ file with scripts permission:\r\n\r\n  \r\n\r\n    FROM python:3.8.9-alpine as builder\r\n    \r\n    \r\n    ENV PYTHONDONTWRITEBYTECODE 1\r\n    ENV PYTHONNUNBUFFERED 1\r\n    \r\n    RUN apk update\r\n    RUN apk add postgresql-dev gcc python3-dev musl-dev libc-dev linux-headers\r\n    \r\n    RUN apk add jpeg-dev zlib-dev libjpeg\r\n    \r\n    RUN pip install --upgrade pip\r\n    COPY ./requirements.txt .\r\n    RUN pip wheel --no-cache-dir --no-deps --wheel-dir /wheels -r requirements.txt\r\n    \r\n    \r\n    \r\n    #### FINAL ####\r\n    \r\n    FROM python:3.8.9-alpine\r\n    \r\n    RUN mkdir /app\r\n    COPY . /app\r\n    WORKDIR /app\r\n    \r\n    RUN apk update && apk add libpq\r\n    COPY --from=builder ./wheels /wheels\r\n    COPY --from=builder ./requirements.txt .\r\n    RUN pip install --no-cache /wheels/*\r\n    #RUN pip install -r requirements.txt\r\n    \r\n    \r\n    COPY ./scripts /scripts\r\n    RUN chmod +x /scripts/*\r\n    \r\n    RUN mkdir -p /vol/media\r\n    RUN mkdir -p /vol/static\r\n    \r\n    #RUN adduser -S user\r\n    \r\n    #RUN chown -R user /vol\r\n    \r\n    RUN chmod -R 755 /vol\r\n    #RUN chown -R user /app\r\n    #RUN chmod -R 755 /app\r\n    \r\n    #USER user\r\n    \r\n    ENTRYPOINT [\"/scripts/entrypoint.prod.sh\"]\r\n    \r\n\r\n  \r\n\r\nHere we used multi-stage build as it reduces final image size. 'builder' is temporary image that's used just to build python wheels with dependencies, that is copied to Final stage. we can create non-root user. Because that is the best practice to be safe from attackers. Now, update the compose production file with docker production file:\r\n\r\n  \r\n\r\n    version: '3.5'\r\n    \r\n    services:\r\n        app:\r\n            build:\r\n                context: .\r\n                dockerfile: Dockerfile.prod\r\n            command: gunicorn personal.wsgi:application --bind 0.0.0.0:8000\r\n            volumes:\r\n                - static_data:/vol/static\r\n            expose:\r\n                - \"8000:8000\"\r\n            restart: always\r\n            env_file:\r\n                - .env.prod\r\n            depends_on:\r\n                - app-db\r\n    \r\n        app-db:\r\n            image: postgres:12-alpine\r\n            ports:\r\n                - \"5432:5432\"\r\n            restart: always\r\n            volumes:\r\n                - postgres_data:/var/lib/postgresql/data:rw\r\n            env_file:\r\n                - .env.prod\r\n    volumes:\r\n        static_data:\r\n        postgres_data:\r\n    \r\n\r\n  \r\n\r\nRebuild, and run:\r\n\r\n    $ docker-compose -f docker-compose.prod.yml down -v\r\n    $ docker-compose -f docker-compose.prod.yml up -d --build\r\n    $ docker-compose -f docker-compose.prod.yml exec app python manage.py migrate --noinput\r\n\r\n  \r\n\r\nNgnix\r\n\r\nNginx, really gives you the ultimate power. You can do whatever you want. Let's add nginx to act as reverse proxy for Gunicorn. Add service on docker compose file (production):\r\n\r\n    version: '3.5'\r\n    \r\n    services:\r\n        app:\r\n            build:\r\n                context: .\r\n                dockerfile: Dockerfile.prod\r\n            command: gunicorn personal.wsgi:application --bind 0.0.0.0:8000\r\n            volumes:\r\n                - static_data:/vol/static\r\n                - media_data: /vol/media\r\n            ports:\r\n                - \"8000:8000\"\r\n            restart: always\r\n            env_file:\r\n                - .env.prod\r\n            depends_on:\r\n                - app-db\r\n    \r\n        app-db:\r\n            image: postgres:12-alpine\r\n            ports:\r\n                - \"5432:5432\"\r\n            restart: always\r\n            volumes:\r\n                - postgres_data:/var/lib/postgresql/data:rw\r\n            env_file:\r\n                - .env.prod\r\n    \r\n        proxy:\r\n            build: ./proxy\r\n            volumes:\r\n                - static_data:/vol/static\r\n                - media_data:/vol/media\r\n            restart: always\r\n            ports:\r\n                - \"8008:80\"\r\n            depends_on:\r\n                - app\r\n    volumes:\r\n        static_data:\r\n        media_data:\r\n        postgres_data:\r\n    \r\n\r\n  \r\n\r\nInside root directory create a proxy(whatever you want to name it) directory and add a configuration file, in my case I have created default.conf file as:\r\n\r\n  \r\n\r\n    server {\r\n        listen 80;\r\n    \r\n        location /static {\r\n            alias /vol/static;\r\n        }\r\n    \r\n        location /media {\r\n            alias /vol/media;\r\n        }\r\n    \r\n    \r\n        location / {\r\n            uwsgi_pass app:8000;\r\n            include /etc/nginx/uwsgi_params;\r\n        }\r\n    }\r\n    \r\n\r\n  \r\n\r\nAnd create uwsgi\\_params file for this.\r\n\r\n    uwsgi_param QUERY_STRING $query_string;\r\n    uwsgi_param REQUEST_METHOD $request_method;\r\n    uwsgi_param CONTENT_TYPE $content_type;\r\n    uwsgi_param CONTENT_LENGTH $content_length;\r\n    uwsgi_param REQUEST_URI $request_uri;\r\n    uwsgi_param PATH_INFO $document_uri;\r\n    uwsgi_param DOCUMENT_ROOT $document_root;\r\n    uwsgi_param SERVER_PROTOCOL $server_protocol;\r\n    uwsgi_param REMOTE_ADDR $remote_addr;\r\n    uwsgi_param REMOTE_PORT $remote_port;\r\n    uwsgi_param SERVER_ADDR $server_addr;\r\n    uwsgi_param SERVER_PORT $server_port;\r\n    uwsgi_param SERVER_NAME $server_name;\r\n    \r\n\r\n  \r\n\r\nAlso add a Dockerfile inside proxy directory for nginx configuration:\r\n\r\n    FROM nginxinc/nginx-unprivileged:1-alpine\r\n    \r\n    COPY ./default.conf /etc/nginx/conf.d/default.conf\r\n    COPY uwsgi_params /etc/nginx/uwsgi_params\r\n    \r\n\r\n  \r\n\r\nYou can use expose instead of ports in docker-compose.prod.yml file for app service:\r\n\r\n        app:\r\n            build:\r\n                context: .\r\n                dockerfile: Dockerfile.prod\r\n            command: gunicorn personal.wsgi:application --bind 0.0.0.0:8000\r\n            volumes:\r\n                - static_data:/vol/static\r\n                - media_data:/vol/media\r\n            expose:\r\n                - 8000\r\n            restart: always\r\n            env_file:\r\n                - .env.prod\r\n            depends_on:\r\n                - app-db\r\n    \r\n\r\n  \r\n\r\nAgain, re-build run and try:\r\n\r\n    $ docker-compose -f docker-compose.prod.yml down -v\r\n    $ docker-compose -f docker-compose.prod.yml up -d --build\r\n    $ docker-compose -f docker-compose.prod.yml exec web python manage.py migrate --noinput\r\n    $ docker-compose -f docker-compose.prod.yml exec web python manage.py collectstatic --no-input --clear\r\n    \r\n\r\nEnsure app is running in [http://localhost:8008.](http://localhost:8008.)\r\n\r\nThat's it.", "publish": "2022-01-25T20:42:30Z", "created_on": "2021-06-04T13:45:38.166Z", "status": 1, "visit_num": 1372, "keywords": "Python", "categories": [2]}}, {"model": "blogs.post", "pk": 6, "fields": {"title": "GAN(VQGAN)  + CLIP Architecture", "slug": "vqgan-clip-architecture", "author": ["sagar"], "updated_on": "2022-11-22T15:28:42.981Z", "short_desciption": "text to image with two advanced architecture", "image": "media/images/bull_and_man_fyxxat_trjhga", "content": "What’s up, guys!!\r\n\r\nToday, I’m now going to work with a multi-modal deep learning architecture called clip that is going to link text with visual elements. I’ll be combining it with a generative model, a transformer type of architecture so that I can take a text prompt and generate visuals and images, even make videos of sequences from that text prompt.\r\n\r\nLet’s work with two cutting-edge generative architectures that are going to allow us to do multi-modal generation. The ability to connect different modalities, in this case, text and images. Text and visual elements with a combination of two architectures: CLIP Architecture (by OpenAI) and Taming Transformers\r\n\r\n### **CLIP Architecture:**\r\n\r\nLearning transferable visual models from natural language supervision and CLIP means Contrastive Language Image Pre-training.\r\n\r\nThe trained model predicts which encoding of text and what text encoding corresponds with what encoding of what a visual encoding.\r\n\r\n\r\n[ Sources: [CLIP GitHub,](https://github.com/openai/CLIP) [CLIP Paper](https://arxiv.org/abs/2103.00020), [blog](https://openai.com/blog/clip/) ]\r\n\r\n### **Taming Transformers:**\r\n\r\nType of generative architecture that can create and invent text to follow the text prompt with more and more text. This is a different kind of transformer that uses an architecture called VQGAN. It combines elements of convolutional architecture with GAN types of elements. It uses a codebook, works with patches.\r\n\r\nCreating the sequence of text elements is not very difficult but images have a very large no. of pixels which leads to the creation of long sequences in transformers. \r\n\r\nBut we can solve this by using - by working with patches. 16 x 16 patches of pixels so we reduce the dimensionality of the problem.\r\n\r\nCodebook trains the network to learn matrices instead of working with pixels directly. It learns kinds of representations of parts of the image that are stored in the codebook, and then when it does generate through the decoder, it works by taking parts of the codebook. (It has different parts, convolutional, decoder, etc.)\r\n\r\n\r\n### **Optimization Process:**\r\n\r\nTake the text phrase and pass it through the CLIP architecture to encode it. And get that encoding in 512 numbers (encoding of the Architecture, understanding of CLIP architecture of that text). Do the same thing with the image, but instead of sending the image as it is, augment it, rotate it, move it or create crops of it (20, 30, 40, 50,….). In this case, I’m gonna create 30 different crops. It is done to help the architecture to understand the image better by giving it multiple versions of it. So, I’m gonna send 30 crops of image clips (with specific rotations, translations) and encode its understanding of those crops. 30 sets of encodings or 512 values.\r\n\r\nNow I’m gonna compare those encodings by using the function cosine similarity, a mathematical function that is used to calculate the similarity of mathematical vectors. It will help to calculate loss value, the performance of the network.\r\n\r\nIf I managed to get the encoding of the text as similar as possible to the encoding of the crops of the image, it would mean that the content of the image matched the content of the text.\r\n\r\n\r\n##### **Include Prompt:**\r\n\r\nWhat we want in the result:\r\n\r\n*   An elephant in a mountain\r\n*   100 people with bluejackets\r\n*   Two people playing football\r\n\r\n##### **Exclude Prompt:**\r\n\r\nWhat we don’t want in the result:\r\n\r\n*   Don’t want to have a blue color in the image.\r\n*   Don’t want to have confusing things in the image.\r\n\r\n##### **Extra Prompt:**\r\n\r\nWhat we want to apply to all of our include prompts:\r\n\r\nEg.\r\n\r\n##### **Include prompts:**\r\n\r\n*   A lad with a pink jacket.\r\n*   A boy playing chess\r\n*   An elephant with green legs\r\n\r\n##### **Extra prompts:**\r\n\r\n*   Watercolor paper texture\r\n\r\nThen watercolor paper texture will be applied to all of the include prompts.\r\n\r\nThen send them to clip to encode and eventually during the optimization, calculate the loss. Give some weight to the encoding of include texts and exclude ones to penalize so that one that should be excluded should increase value and one that should be included should decrease the loss value.\r\n\r\n\r\nAlso, one can begin the generation from a specific image/picture instead of noise input, and modify, edit that image in the direction specified by the text prompt.\r\n\r\n\r\nIn this,\r\n\r\nAfter generating new images, I’m gonna show you the capability of creating interpolations between the latent parameters generated by the process and then produce a video that shows the interpolations from one of the creations to other creations, and then show the video on a screen.\r\n\r\n\r\n\r\n## Coding and Execution:\r\n\r\n\r\n```python\r\n# Multimodal A.I. CLIP+VQGAN\r\n\r\n!git clone https://github.com/openai/CLIP.git\r\n#Learning Transferable Visual Models From Natural Language Supervision\r\n!git clone https://github.com/CompVis/taming-transformers\r\n#Taming Transformers for High-Resolution Image Synthesis\r\n```\r\n\r\n\r\nOutput:\r\n\r\n![](https://lh6.googleusercontent.com/TLfKuXi1tlspNSOh31yq1Q-ROUVVwmmgiaULxO0Mmen8rho1YgRLF5poALSV7_dp8A3jNxmH_KYG2UbNV1YQfDCoG8b5TID9i46yarYZAh7B3nqmGsmQlAw-3jRqnBgUsWdT7DVr)\r\n\r\n##### Install some libraries:\r\n\r\n```python\r\n## install some extra libraries  \r\n!pip install --no-deps ftfy regex tqdm  \r\n!pip install omegaconf==2.0.0 pytorch-lightning==1.0.8  \r\n!pip uninstall torchtext --yes  \r\n!pip install einops\r\n```\r\n\r\nOutput:\r\n\r\n![](https://lh3.googleusercontent.com/VezEthYOunl-znVOWoPohNFtFPbg27Xor-NnrP3tLH5Apv3-8uN3Z_d6dZiDoPHyJnvI_r6F9Atqdckt6wzIC3lgVqBGPeqtsQrUOskP4o-QmYhCd6ZcG1lxamUf8ZrOqtr6tLPZ)\r\n\r\n##### Import libraries:\r\n\r\n```python\r\n# import libraries  \r\nimport numpy as np  \r\nimport torch, os, imageio, pdb, math  \r\nimport torchvision  \r\nimport torchvision.transforms as T  \r\nimport torchvision.transforms.functional as TF  \r\n  \r\nimport PIL  \r\nimport matplotlib.pyplot as plt\r\n\r\n  \r\nimport yaml  \r\nfrom omegaconf import OmegaConf\r\n\r\n  \r\nfrom CLIP import clip  \r\n  \r\n#import warnings  \r\n#warnings.filterwarnings('ignore')\r\n\r\nHelper functions:\r\n\r\ndef ShowFromTensor(tensor):  \r\n  img = tensor.clone()  \r\n  img = img.mul(255).byte()  \r\n  img = img.cpu().numpy().transpose((1,2,0))  \r\n  \r\n  plt.figure(figsize=(10,7))  \r\n  plt.axis('off')  \r\n  plt.imshow(img)  \r\n  plt.show()  \r\n  \r\ndef NormData(data):  \r\n  return (data.clip(-1,1)+1)/2 ### range between 0 and 1 in the result  \r\n  \r\n### Parameters  \r\nlearning_rate = .5  \r\nbatch_size = 1  \r\nwd = .1 # (weight decay is regularization parameter, help to limit the size of weight and improve generalization capabilities of the architecture)  \r\n  \r\n\r\nnoise_factor = .22  \r\n  \r\ntotal_iter=100 # use more no. of iterations for more polished result  \r\nim_shape = [450, 450, 3] # height, width, channel  \r\nsize1, size2, channels = im_shape\r\n\r\nNow create CLIP model:\r\n\r\n### CLIP MODEL ###  \r\nclipmodel, _ = clip.load('ViT-B/32', jit=False)  \r\nclipmodel.eval()  \r\nprint(clip.available_models())  \r\n  \r\nprint(\"Clip model visual input resolution: \", clipmodel.visual.input_resolution)  \r\n  \r\ndevice=torch.device(\"cuda:0\")  \r\ntorch.cuda.empty_cache()\r\n```\r\n\r\nOutput:\r\n\r\n![](https://lh4.googleusercontent.com/jZ-BTyKZXkK7WxCfMLuCtecU032p8j0Ek-n4EAyrKHYksviBMsW0VI5_5HsABGWPj_db4U9WbNkgZEOy3_zmaVO3tuVsXkwM6SNIiyqzjI96JZTt1AiNfqyQQ1V6WIvmumnoymaG)\r\n\r\nThe CLIP downloads a pre-trained model, so we don’t need to train CLIP, we can proceed to use it in inference, eval mode to encode texts and images directly. \r\n\r\n  \r\n\r\n['RN50', 'RN101', 'RN50x4', 'RN50x16', 'ViT-B/32', 'ViT-B/16']  are types of architectures that CLIP can use internally. (eg. RN50 - resNet architecture with 50 layers, ViT-B/32 - Visual Transformer)\r\n\r\n  \r\n\r\nAnd clip Model visual input resolution 224 pixels. This means, when we encode images in CLIP, we need to set them to 224 pixels.\r\n\r\n  \r\n\r\n  \r\n\r\n##### **Taming transformer model:**\r\n\r\n```python\r\n## Taming transformer instantiation  \r\n  \r\n%cd taming-transformers/  \r\n  \r\n!mkdir -p models/vqgan_imagenet_f16_16384/checkpoints  \r\n!mkdir -p models/vqgan_imagenet_f16_16384/configs  \r\n  \r\nif len(os.listdir('models/vqgan_imagenet_f16_1684/checkpoints/')) == 0:  \r\n  !wget 'https://heibox.uni-heidelberg.de/f/867b05fc8c481768640/?dl=1' -O 'models/vqgan_imagenet_f16_16384/checkpoints/last.ckpt'  \r\n  !wget 'https://heibox.uni-heidelberg.de/f/274fb2ed38341bfa753/?dl=1' -O 'models/vqgan_imagenet_f16_1684/configs/model.yaml' \r\n```\r\n  \r\n\r\nHere, vqgan_imagenet_f16_16384 means VQGAN image net is trained with images from the image metadata set f-16 because the file is named using downsampling factor f16 for each. And 16384 is codebook dimensionality.\r\n\r\n Now create two checkpoints and configs folders if they don’t exist already.\r\n\r\nBoth links heidelberg.de are working to date in Nepal, but if they don’t work in the future there should be some alternative. \r\n\r\nBy running this, it downloads Heidelberg’s pre-trained VQGAN model, last checkpoints and configuration information that will be in model.yaml file.\r\n\r\n  \r\n\r\nOutput:\r\n\r\n![](https://lh4.googleusercontent.com/057Y_hDJZWWfKma67VLcESDJSpms6Qi2t0AzDj03l9P5FyTDPDt90azrheEyttKX0qrInjeojLNv187pGqpD2iNFmbVeCHr__f1RVgyikZoLjl5uTBNX-lweemXILAL7CqV2ch0L)\r\n\r\nNow after downloading the checkpoint, let’s instantiate the **Taming transformer VQGAN architecture**.\r\n\r\n```python\r\nfrom taming.models.vqgan import VQModel  \r\n  \r\ndef LoadConfig(config_path, display=False):  \r\n  config_data = OmegaConf.load(config_path)  \r\n  if display:  \r\n    print(yaml.dump(OmegaConf.to_container(config_data)))  \r\n  return config_data  \r\n  \r\ndef LoadVQGAN(config, chk_path=None):  \r\n  model = VQModel(**config.model.params)  \r\n  if chk_path is not None:  \r\n    state_dict = torch.load(chk_path, map_location=\"cpu\")[\"state_dict\"]  \r\n    missing, unexpected = model.load_state_dict(state_dict, strict=False)  \r\n  return model.eval()  \r\n  \r\ndef Generator(x):  \r\n  x = taming_model.post_quant_conv(x)  \r\n  x = taming_model.decoder(x)  \r\n  return x  \r\n  \r\ntaming_config=LoadConfig(\"./models/vqgan_imagenet_f16_16384/configs/model.yaml\", display=True)  \r\ntaming_model = LoadVQGAN(taming_config, chk_path=\"./models/vqgan_imagenet_f16_16384/checkpoints/last.ckpt\").to(device)\r\n```\r\n  \r\n\r\nFirst, create a function for load configuration using library OmegaConf and dump to YAML file to see the configurations.\r\n\r\n  \r\n\r\nSecond, create another function to load the VQGAN model. Use the previously imported model with the config file. Load state\\_dict dictionary that contains all the parameters of the model. And load checkpoint with path, map location to “CPU”. Now load the dictionary into the model.\r\n\r\nHere, we’re going to use a model directly, no need to train so put it in evaluation or eval() mode.\r\n\r\n  \r\n\r\nThe third and last function is Generator. Take input and generate images from it. For this input is passed through the taming model and output is passed to the decoder.\r\n\r\n  \r\n\r\nThen load configurations on the model.\r\n\r\n  \r\n\r\n(The models folder is within the taming-transformers folder as we did before, so paths are relative to the content of that folder)\r\n\r\n\r\n\r\nOutput:\r\n\r\n![](https://lh5.googleusercontent.com/Xt2B4KzAROjrmMTWyXfKo3euKE-U7M86JGVxhJGm-uuQu4Bmm71ztY67e3vLowupPqjfoi0ekw6pb4csRXC3aRS0oxPQ8AtyVZIdwUyjcdXxAM2h3tvk4vQY9TUeSu3mF_6B4piR)\r\n\r\n\r\nDeclare the values (Latent space, parameters) that we are going to optimize:  \r\n\r\n```python\r\nclass Parameters(torch.nn.Module):  \r\n  def __init__(self):  \r\n    super(Parameters, self).__init__()  \r\n    self.data = .5*torch.randn(batch_size, 256, size1//16, size2//16).cuda() # 1x256x28.125x28.125 (450/16, 450/16)  \r\n    self.data = torch.nn.Parameter(torch.sin(self.data))  \r\n  \r\n  def forward(self):  \r\n    return self.data  \r\n  \r\ndef init_params():  \r\n  params=Parameters().cuda()  \r\n  optimizer = torch.optim.AdamW([{'params':[params.data], 'lr': learning_rate}], weight_decay=wd)  \r\n  return params, optimizer\r\n\r\n```\r\n  \r\nInitialize data with random numbers from a normal distribution with parameters as batch size, channels, and size, where size is divided by 16 because of requirement(16 x 16 patches). For tensor of random value 1, it will be 1x256x28.125x28.125. (450/16 = 28.125, 450/16 = 28.125)\r\n\r\n\r\nHere, multiplying by .5 is because personally experimentally it is found to be good before taking data from a normal distribution.\r\n\r\n\r\nThen, in recurrent neural networks, they have clear indications of the positioning of the elements based on architecture itself but in transforming architectures, you just push all the data at once. Which means it is the use of periodic mathematical functions to embed positioning information within the data. And we’re using mathematical sine.\r\n\r\n\r\nCreate a forward function which returns data just called.\r\n\r\n\r\nFinally, create a helper function. In this call that function(Parameters), on-call refresh and reset those parameters then declare optimizer. (Adam optimizer is used for this.)\r\n\r\nEncoding of text prompts in CLIP architecture:\r\n\r\n```python\r\n### Encoding prompts and a few more things  \r\nnormalize = torchvision.transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))  \r\n  \r\ndef encodeText(text):  \r\n  t=clip.tokenize(text).cuda()  \r\n  t=clipmodel.encode_text(t).detach().clone()  \r\n  return t  \r\n  \r\ndef createEncodings(include, exclude, extras):  \r\n  include_enc=[]  \r\n  for text in include:  \r\n    include_enc.append(encodeText(text))  \r\n  exclude_enc=encodeText(exclude) if exclude != '' else 0  \r\n  extras_enc=encodeText(extras) if extras !='' else 0  \r\n  \r\n  return include_enc, exclude_enc, extras_enc  \r\n  \r\naugTransform = torch.nn.Sequential(  \r\n    torchvision.transforms.RandomHorizontalFlip(),  \r\n    torchvision.transforms.RandomAffine(30, (.2, .2), fill=0)   \r\n).cuda()  \r\n  \r\nParams, optimizer = init_params()  \r\n  \r\nwith torch.no_grad():  \r\n  print(Params().shape)  \r\n  img= NormData(Generator(Params()).cpu()) # 1 x 3 x 448 x 448 [450 x 450]  \r\n  print(\"img dimensions: \",img.shape)  \r\n  ShowFromTensor(img[0])\r\n```\r\n\r\n\r\nHere, normalizing is required in this architecture so define a variable and use values for the mean, variance that has been prepared already for us.\r\n\r\n\r\nCreate a function that receives the text then calls CLIP model to tokenize the text. Pass result through the encode function of the model and detach the result from the computation of gradients and will clone the results so that we can use our own memory space on the variable.\r\n\r\n\r\nNow define a generic function that will be applied to exclude, include, and extras of our prompts. \r\n\r\nWhen sending the image to encode, we’re not gonna send a single image. We also send a set of crops of the image. To declare a variable for augmentation transformation of the image. After doing some random rotations then some translations and remaining are filled with zeros. \r\n\r\n\r\nNote: The augmentations are first applied to the single image produced by the generator and then from that output, the different crops are created.\r\n\r\n\r\nInitialize parameters and optimizer and make a simple test to generate an image through a transformer generator with random initial parameters. Call generator function and pass parameters we declared before and put the result back on the CPU. It will return 1 in the first dimension then three channels, 448, 448. (1 x 3 x 448 x 448 \\[450, 450\\] but we get 448 due to rounding.)\r\n\r\n\r\nOutput:\r\n\r\n![](https://lh5.googleusercontent.com/zMWkGaFoU0Y4QHiFitthmafmfol-y5oZXPdmagBD1slNQ4c5Pd8LkrPQBCKOh8bfmjqIjjW-4ETnYjB2H5AX13qyrAZpUgDoId0B7cAZT6aeu63fsUTDqGnAO5xxIf-jkrLLss4v)\r\n\r\n##### **Create crops:**\r\n\r\n```python\r\ndef createCrops(img, num_crops=32):\r\n  p=size1//2\r\n  img = torch.nn.functional.pad(img, (p,p,p,p), mode='constant', value=0) # 1 x 3 x 448 x 624 (adding 112*2 on all sides to 224x400)  \r\n  \r\n  img = augTransform(img) #RandomHorizontalFlip and RandomAffine\r\n  \r\n  crop_set = []  \r\n  for ch in range(num_crops):\r\n    gap1= int(torch.normal(1.2, .3, ()).clip(.43, 1.9) * size1) # you can change values to optimize your result later on\r\n\r\n    # gap2= int(torch.normal(1.2, .3, ()).clip(.43, 1.9) * size1)\r\n    offsetx = torch.randint(0, int(size1*2-gap1),())\r\n    offsety = torch.randint(0, int(size1*2-gap1),())\r\n  \r\n    crop=img[:,:,offsetx:offsetx+gap1, offsety:offsety+gap1]\r\n  \r\n    crop = torch.nn.functional.interpolate(crop,(224,224), mode='bilinear', align_corners=True)  \r\n    crop_set.append(crop)  \r\n  \r\n  img_crops=torch.cat(crop_set,0) ## 30 x 3 x 224 x 224\r\n  \r\n  randnormal = torch.randn_like(img_crops, requires_grad=False)\r\n  num_rands=0  \r\n  randstotal=torch.rand((img_crops.shape[0],1,1,1)).cuda() #32\r\n   \r\n  for ns in range(num_rands):  \r\n    randstotal*=torch.rand((img_crops.shape[0],1,1,1)).cuda()\r\n  \r\n  img_crops = img_crops + noise_factor*randstotal*randnormal\r\n  \r\n  return img_crops\r\n```\r\n\r\nCreate a function called createCrops. And let’s set default value 32 for no. of crops value. Add some padding around the image so that we can rotate, translate and preserve image information.\r\n\r\nLet’s set padding as height divided by 2 or 3. Then set padding on all sides as (p,p,p,p). So the dimension will be 1 x 3 x (448+112+112) x (448+112+112) = 1 x 3 x 672 x 672.\r\n\r\n\r\nNow apply previously declared augmentations transformations (augTransforms). Set crops that is empty initially. Define a couple of variables or no. of pixels or numbers to use for offset and also for the amount of crop, here is gap1, gap2 defined. \r\n\r\nCrop image keeping first two dimensions as they are and change last two dimensions as extended with gap1.\r\n\r\nResize crop to 224x224 and accumulate to crops dictionary we defined previously. Resolution will be 30 x 3 x 224 x 224.\r\n\r\nFinally, add some noise to the crop. With noise factor and some random values from a normal distribution of the same dimensionality.\r\n\r\n  \r\n\r\n##### **Davinci Sfumato texture:-**\r\n\r\nThe lines that are in the above code are actually for the sfumato effect. (You will know at the end.)\r\n\r\n```python\r\n  randnormal = torch.randn_like(img_crops, requires_grad=False)\r\n  num_rands=0  \r\n  randstotal=torch.rand((img_crops.shape[0],1,1,1)).cuda() #32  \r\n   \r\n  for ns in range(num_rands):  \r\n    randstotal*=torch.rand((img_crops.shape[0],1,1,1)).cuda()\r\n  img_crops = img_crops + noise_factor*randstotal*randnormal\r\n```\r\n\r\n\r\n[ Note: Davinci [Sfumato](https://en.wikipedia.org/wiki/Sfumato#:~:text=Sfumato%20(Italian%3A%20%5Bsfu%CB%88ma%CB%90to%5D,out%2Dof%2Dfocus%20plane.) \\]\r\n\r\n\r\nLet’s create a function to see the generated image at any state:\r\n\r\n```python\r\n### Show current state of generation\r\n  \r\ndef showMe(Params, show_crop):\r\n  with torch.no_grad():\r\n    generated = Generator(Params())\r\n\r\n    if (show_crop):\r\n      print(\"Augmented cropped example\")\r\n      aug_gen = generated.float() # 1 x 3 x 224 x 400\r\n      aug_gen = createCrops(aug_gen, num_crops=1)\r\n      aug_gen_norm = NormData(aug_gen[0])\r\n      ShowFromTensor(aug_gen_norm)\r\n\r\n    print(\"Generation\")\r\n    latest_gen=NormData(generated.cpu()) # 1 x 3 x 224 x 400  \r\n    ShowFromTensor(latest_gen[0])\r\n\r\n  return (latest_gen[0])\r\n```\r\n\r\n\r\nLet’s don’t involve gradient here. Pass parameters that we’re used for the optimization of generator, to generate an example image at the current state of the parameters. (1 x 3 x 450 x 450)\r\n\r\n\r\nAnd now call createCrops function to create crops but only one crop. Normalize the result and show.\r\n\r\nThen for generation, the latest generation is going to normalize what we already generated. Finally, show the image.\r\n\r\n\r\nOptimizing the mode by tweaking the parameters:\r\n\r\n```python\r\n# Optimization process\r\n\r\ndef optimizeResult(Params, prompt):\r\n  alpha=1 ## the importance of the include encodings\r\n  beta=.5 ## the importance of the exclude encodings\r\n\r\n  ## image encoding\r\n  out = Generator(Params())\r\n  out = NormData(out)\r\n  out = createCrops(out)\r\n  out = normalize(out) # 32 x 3 x 448 x 448\r\n  image_enc=clipmodel.encode_image(out) ## 32 x 512\r\n\r\n  ## text encoding  w1 and w2\r\n  final_enc = w1*prompt + w1*extras_enc # prompt and extras_enc : 1 x 512\r\n  final_text_include_enc = final_enc / final_enc.norm(dim=-1, keepdim=True) # 1 x 512  \r\n  final_text_exclude_enc = exclude_enc\r\n\r\n  ## calculate the loss\r\n  main_loss = torch.cosine_similarity(final_text_include_enc, image_enc, -1) # 32\r\n  penalize_loss = torch.cosine_similarity(final_text_exclude_enc, image_enc, -1) # 32  \r\n\r\n  final_loss = -alpha*main_loss + beta*penalize_loss\r\n\r\n  return final_loss\r\n\r\ndef Optimize(Params, optimizer, prompt):\r\n  loss = optimizeResult(Params, prompt).mean()\r\n  optimizer.zero_grad()\r\n  loss.backward()\r\n  optimizer.step()\r\n  return loss\r\n\r\n```\r\n\r\n\r\nLet’s create a function called Optimize that will gonna receive the current state of the parameters, optimizer, and text prompt. Calculate current loss calling a function optimzeResult which we gonna declare. After this, calculate the mean we are gonna get the loss for each crop and calculate the average of it. Set optimizer to gradient value zero, do backpropagation, and tweak-update to step with values of parameters. So, this is an optimizing function.\r\n\r\nNow, define the optimizeResult function which will find the lost value and lowest value that is gonna drive the optimize function. It’s gonna receive params, and prompt. Declare a couple of variables alpha, beta with values 1 and 0.5 respectively. They will represent the significance or importance of include and exclude encodings resp. (here, since alpha>beta, include will be important than exclude during encodings)\r\n\r\nAfter this generate a new image from parameters and normalize the result.\r\n\r\n[Note: To calculate loss, encodings of text prompts and encodings of image crops generated from the current state of latent space parameters should be compared. So we need to pass parameters through a generator to generate a new image so that we can encode it.\\]\r\n\r\n\r\nAnd create crops, normalize them with extra normalization (for the images to match CLIP architecture). Then create an image encoding by calling the CLIP model. (32 crops composed of 500 so, encoding dimensionality be 512x512)\r\n\r\nW1, W1 are weights for include and extras text encodings. Divide encoding values by their normalization to get them in the correct range.\r\n\r\nNow calculate the loss using cosine similarity mathematical function. Main loss(include), penalize loss(exclude). (each of the 32 crops will be compared with the single encoding of include texts and exclude texts respectively)\r\n\r\nThen total loss will be the summation of both losses as:\r\n\r\nMain loss multiplied by alpha(include factor) AND Penalize loss multiplied by beta(exclude factor).\r\n\r\n\r\nNow it’s time for training loop coding:\r\n\r\n```python\r\n### training loop\r\n\r\ndef trainingLoop(Params, optimizer, show_crop=False):\r\n  res_img=[]\r\n  res_z=[]\r\n\r\n  for prompt in include_enc:\r\n    iteration=0\r\n    Params, optimizer = init_params() # 1 x 256 x 28.125 x 28.125 (450/16, 450/16)\r\n\r\n    for it in range(total_iter):\r\n      loss = Optimize(Params, optimizer, prompt)\r\n\r\n      if iteration>=80 and iteration%show_step == 0: # every show_step after 80 iteration, we will see results  \r\n        new_img = showMe(Params, show_crop)\r\n        res_img.append(new_img)\r\n        res_z.append(Params()) # 1 x 256 x 28.125 x 28.125\r\n        print(\"loss:\", loss.item(), \"\\niteration:\",iteration)\r\n\r\n      iteration+=1\r\n    torch.cuda.empty_cache()\r\n  return res_img, res_z\r\n```\r\n\r\n\r\n\r\nCreate a function that takes parameters, optimizer. Initialize each of the encodings with iteration set to zero. Initialize parameter on every call.\r\n\r\nCalculate the loss calling optimize function defined previously. And display the image as you want. Here, I’m gonna show image 1 iteration before the final iteration. So, call showMe function and declare prompts, increase iterations. In the end, you can delete the cache of GPU.\r\n\r\n\r\n##### It’s SHOWTIME:\r\n\r\n```python\r\ntorch.cuda.empty_cache()\r\n#include=['sketch of a lady', 'sketch of a man on a horse']\r\ninclude=['Sketch of a man on a horse']\r\nexclude='watermark, cropped, confusing, blurry'\r\nextras = \"watercolor paper\"\r\nw1=1\r\nw2=1\r\nnoise_factor= .22\r\ntotal_iter=1000\r\nshow_step=100 # set this to see the result every 10 iterations beyond iteration 80\r\ninclude_enc, exclude_enc, extras_enc = createEncodings(include, exclude, extras)\r\nres_img, res_z=training_loop(Params, optimizer, show_crop=True)\r\n```\r\n\r\nOutput:\r\n\r\nAfter 100 iterations crop and non-crop image results:\r\n\r\n![](https://lh5.googleusercontent.com/fACC_Upmg_mY7VfNxFxjDat_OcqUAl_wzRwD_ZtOpxVE7G-5Nati8EUS3Gh95vAYTaO6OzCcpaIssnBKbHmoE5VFlz5pddEMKdovkYf2crLgiPriIzKTvbV4lOV6Md8RhGa4EfQ7)![](https://lh4.googleusercontent.com/my8KGS9XTPl9B9zuLiotGCtSHxw47kdx3pRs5Hr5XVq-KQFzUpy11gH12KqSX-lADP4NWKfzJ9TjptJ0hYx1sYW6Pk1FJZqcc8G4Z8Pea2ulrywPdO2y3PCZUe9TVhJ6CiGbZeMW)\r\n\r\nAfter 300 iterations:\r\n\r\n![](https://lh6.googleusercontent.com/gySiS9h4OTJDAfixo2-ClCI9_8EZWKuS1C4dqvkRLNIvDJSGSYaqmBH5hGQ7AExW9HSe7pjjUg5Blear2tEBnrc_WxAiELKldvIO56mUuTwO6QIRzpcUeq7abXbb5m1Ni9HeMoAW)![](https://lh6.googleusercontent.com/PLLjp1N9bHvL9cz_wrB73PEqyIFycLDM-0vjfbA3EomthE9QIuoyZjT_HiHLc8vro3cFeQwv4yO4b3V0bya0HKopquA-NmuiLrUgt3xlfcx0GDt3rN_ooF4JW99rWWJvSD_3eXNV)\r\n\r\nAnd so on…\r\n\r\n\r\nIf you refresh and re-run from starting, it will show different images on the same step. It is because we’re using stochastic processes not deterministic.\r\n\r\n\r\nCheck resulting images dimensionalities:\r\n\r\n```python\r\nprint(len(res_img), len(res_z))  \r\nprint(res_img[0].shape, res_z[0].shape)  \r\nprint(res_z[0].max(), res_z[0].min())\r\n```\r\n\r\nOutput:\r\n\r\n![](https://lh5.googleusercontent.com/E9kzxwwG0qwIu-46qz_DdTCQueLkE0fCU7DA0wEvJZRMOrE37cFvhrcFZ4VFNG5kc4tw0PvUNl21ptwokhlJ4uNY7ub5svtrEIJpi9EY-0iMwRfXiZ5dg1PyDZmEnhNdDPP14q9N)\r\n\r\nLet’s see another example:\r\n\r\n\r\nInclude: “A man fighting with a bull”\r\n\r\nExclude: “Watermark, blurry, cropped, confusing, cut, incoherent”\r\n\r\nExtra: “ ”\r\n\r\n![](https://lh4.googleusercontent.com/47RraXQodo6LrOF8ABSBpYeclx3oTbYPJ_Cn7pXp-EmXSWD4IGhpRoQKp2S33iQYe05GTz5sf9xkhAfLUliS9L9f1cp2kcyQaf3l4jYFbQkJgUUiYgyQRTU7zMkmAdFroH1cwCsA)![](https://lh3.googleusercontent.com/pxhFIK7aQQhtcCR7e_BX4I3zWT9PJBZYPtt_MA8lV2e8Q3qE58X0JWRbDp49ge7IDeZMiwFvVkfxOkiMLJ44P0YKXQjQAAAvlztObcnLD7f77SRmSw3txe0o0xb82yKd1kzYD_dq)\r\n\r\nExcellent !!\r\n\r\n\r\n[The best generation might not be the last one always… It could be one of previous]\r\n\r\n\r\nAt last,\r\n\r\nMultiple prompts and results:\r\n\r\n\r\nInclude: [ “A man fighting with a bull”, “A dog sleeping in the park”, “People striking in the road”]\r\n\r\nExclude: “Watermark, blurry, cropped, confusing, cut, incoherent”\r\n\r\nExtra: “ ”\r\n\r\n\r\n\r\nThank you!\r\n\r\nNext: Creating video from multiple representations/results.", "publish": "2022-01-25T20:42:30Z", "created_on": "2021-08-15T21:31:31.417Z", "status": 1, "visit_num": 1209, "keywords": "Python", "categories": [1]}}, {"model": "blogs.post", "pk": 8, "fields": {"title": "OpenVPN Access Server(self-hosted) set-up on AWS EC2", "slug": "openvpn-access-serverself-hosted-set-up-on-aws-ec2", "author": ["sagar"], "updated_on": "2022-11-23T09:21:11.180Z", "short_desciption": "OpenVPN Access Server setup on AWS EC2", "image": "media/images/Selection_006_j5cyvj", "content": "Nowadays, hiding identity, remotely accessing the company or server, Inside IoT security etc are the challenges we face each day. We can use OpenVPN as an SSH whitelisting so we can access/ssh the servers or instances only when we’re connected to the VPN.\r\n\r\nOpenVPN is not completely free.\r\n\r\nTo set up OpenVPN on AWS EC2 we can use different types of Linux machines such as Ubuntu, CentOS, Amazon Linux etc. For this tutorial, I’m going to use AWS Marketplace AMIs(pre-baked AMIs). Even though the instance is pre-baked, setting up OpenVPN might be a little tricky. So. I’m going to cover those step by step.\r\n\r\n  \r\n\r\nCreate Instance using AWS Marketplace AMI:\r\n------------------------------------------\r\n\r\n*   Go to your console and select the region you want your OpenVPN instance to be in.\r\n*   Select EC2 service and search **_OpenVPN_** to launch a new instance from _**AWS Marketplace.**_ It will show official OpenVPN AMIs from AWS Marketplace.\r\n\r\n![](https://res.cloudinary.com/sbmagar-media-storage/image/upload/v1/media/django-summernote/2022-02-14/22cf6e75-7264-4429-9efe-17c24d1d34ae_rnfttn)  \r\n\r\n*   Now select one of the _**OpenVPN Access Server**_ from the list. For this, I’m going to select the first one with _**t2.micro**_ instance type.\r\n*   (**Important**)Configure all of the instance details as per your requirements. During the configuration, make sure you choose your VPC and subnet. If you don’t have custom VPC and subnets, leave all these settings as is. Make sure that OpenVPN server instance is in public subnet so it is accessible via the web directly.\r\n*   Create a security group for the OpenVPN Server in which save rules AWS already has filled.\r\n\r\n![](https://res.cloudinary.com/sbmagar-media-storage/image/upload/v1/media/django-summernote/2022-02-14/ca979e3e-0fe0-42cc-b765-f5d570011a8d_ygrzjr)  \r\n\r\n*   Now review and launch the instance. It will run a new instance.  \r\n      \r\nIP and Domain:\r\n--------------\r\n\r\nWhen the instance is up and running, AWS provides public IP automatically. But it will immediately change when you reboot the instance anytime. For this, we can associate an elastic IP to the instance so it stays the same even if the instance is stopped or rebooted.\r\n\r\n*   Go to Elastic IPs section and Allocate a new address.\r\n*   Now you have new elastic IP but not associated with any instance. Associate address selecting your openVPN instance.\r\n*   Save, and you have now elastic IP. Now, you can associate a domain to this public IP.\r\n\r\nIf you want to use a custom domain, make sure you have a domain like [_**vpn.yourdomain.com**_](http://vpn.yourdomain.com)(or any as you wish) to access this server(instance).\r\n\r\nPoint your A record of domain to the elastic IP.  \r\n  \r\n\r\nSetup OpenVPN:\r\n--------------\r\n\r\nYou will not be able to access openVPN server directly as you haven’t set up server. For this you have to ssh into the server:\r\n\r\n*   Use key-pair file _**vpn-keypair.pem**_ (created when launching instance) to ssh into the instance. Open port 22 for all traffic to be able to SSH into the instance. (we can change that later after setup)\r\n*   Use username as _**openvpnas**_ as this is the default with OpenVPN marketplace instance.\r\n*   Once you log in, follow the setup wizard. It will ask no. of settings to you.\r\n\r\n    \t\topenvpnas@ip-address:# \r\n    \r\n    \t\tWelcome to OpenVPN Access Server Appliance 2.8.5\r\n    \r\n    \t\tSystem information as of Sat Feb 11 12:24:42 UTC 2022\r\n    \r\n    \t\tSystem load:  0.95              Processes:           98\r\n    \t\tUsage of /:   26.7% of 7.69GB   Users logged in:     0\r\n    \t\tMemory usage: 18%               IP address for eth0: 172.32.1.87\r\n    \t\tSwap usage:   0%\r\n    \r\n    \t\tOpenVPN Access Server\r\n    \t\tInitial Configuration Tool\r\n    \t\t------------------------------------------------------\r\n    \r\n    \t\tPlease enter 'yes' to indicate your agreement [no]: yes\r\n    \r\n    \t\tOnce you provide a few initial configuration settings,\r\n    \t\tOpenVPN Access Server can be configured by accessing\r\n    \t\tits Admin Web UI using your Web browser.\r\n    \r\n    \t\tWill this be the primary Access Server node?\r\n    \t\t(enter 'no' to configure as a backup or standby node)\r\n    \t\t> Press ENTER for default [yes]: yes\r\n    \r\n    \t\tPlease specify the network interface and IP address to be\r\n    \t\tused by the Admin Web UI:\r\n    \t\t(1) all interfaces: 0.0.0.0\r\n    \t\t(2) eth0: 172.31.16.206\r\n    \t\tPlease enter the option number from the list above (1-2).\r\n    \t\t> Press Enter for default [2]: 1\r\n    \r\n    \t\tPlease specify the port number for the Admin Web UI.\r\n    \t\t> Press ENTER for default [943]: 943\r\n    \r\n    \t\tPlease specify the TCP port number for the OpenVPN Daemon\r\n    \t\t> Press ENTER for default [443]: 443\r\n    \r\n    \t\tShould client traffic be routed by default through the VPN?\r\n    \t\t> Press ENTER for default [yes]: yes\r\n    \r\n    \t\tShould client DNS traffic be routed by default through the VPN?\r\n    \t\t> Press ENTER for default [yes]: yes\r\n    \r\n    \t\tUse local authentication via internal DB?\r\n    \t\t> Press ENTER for default [yes]: yes\r\n    \r\n    \t\tPrivate subnets detected: ['172.31.0.0/16']\r\n    \r\n    \t\tShould private subnets be accessible to clients by default?\r\n    \t\t> Press ENTER for EC2 default [yes]: yes\r\n    \r\n    \t\tTo initially login to the Admin Web UI, you must use a\r\n    \t\tusername and password that successfully authenticates you\r\n    \t\twith the host UNIX system (you can later modify the settings\r\n    \t\tso that RADIUS or LDAP is used for authentication instead).\r\n    \r\n    \t\tYou can login to the Admin Web UI as \"openvpn\" or specify\r\n    \t\ta different user account to use for this purpose.\r\n    \r\n    \t\tDo you wish to login to the Admin UI as \"openvpn\"?\r\n    \t\t> Press ENTER for default [yes]: yes\r\n    \r\n    \t\t> Please specify your OpenVPN-AS license key (or leave blank to specify later):\r\n    \r\n    \t\tInitializing OpenVPN...\r\n    \t\tAdding new user login...\r\n    \t\tuseradd -s /sbin/nologin \"openvpn\"\r\n    \t\tWriting as configuration file...\r\n    \t\tPerform sa init...\r\n    \t\tWiping any previous userdb...\r\n    \t\tCreating default profile...\r\n    \t\tModifying default profile...\r\n    \t\tAdding new user to userdb...\r\n    \t\tModifying new user as superuser in userdb...\r\n    \t\tGetting hostname...\r\n    \t\tHostname: openvpnserver\r\n    \t\tPreparing web certificates...\r\n    \t\tGetting web user account...\r\n    \t\tAdding web group account...\r\n    \t\tAdding web group...\r\n    \t\tAdjusting license directory ownership...\r\n    \t\tInitializing confdb...\r\n    \t\tGenerating init scripts...\r\n    \t\tGenerating PAM config...\r\n    \t\tGenerating init scripts auto command...\r\n    \t\tStarting openvpnas...\r\n    \r\n    \t\tNOTE: Your system clock must be correct for OpenVPN Access Server\r\n    \t\tto perform correctly.  Please ensure that your time and date\r\n    \t\tare correct on this system.\r\n    \r\n    \t\tInitial Configuration Complete!\r\n    \r\n    \t\tYou can now continue configuring OpenVPN Access Server by\r\n    \t\tdirecting your Web browser to this URL:\r\n    \r\n    \t\thttps://ip-address:943/admin\r\n    \t\tLogin as \"openvpn\" with the same password used to authenticate\r\n    \t\tto this UNIX host.\r\n    \r\n    \t\tDuring normal operation, OpenVPN AS can be accessed via these URLs:\r\n    \t\tAdmin  UI: https://ip-address:943/admin\r\n    \t\tClient UI: https://ip-address:943/\r\n    \r\n    \t\tSee the Release Notes for this release at:\r\n    \t\thttps://openvpn.net/vpn-server-resources/release-notes/\r\n    \r\n    \t\t*   Now create password to login first time as an admin, for that:\r\n    \r\n    \t\topenvpnas@10.0.101.94:~$ sudo passwd openvpn\r\n    \t\tEnter new UNIX password:\r\n    \t\tRetype new UNIX password:\r\n    \t\tpasswd: password updated successfully\r\n    \t\topenvpnas@10.0.101.94:~$\r\n\r\nOpenVPN UI:\r\n-----------\r\n\r\nFrom browser visit _**https://<elastic-IP>:943/admin**_, you will get openVPN server UI. And login with the username OpenVPN (created before) and the admin password set earlier. Once you login, accept the terms & conditions.\r\n\r\n![](https://res.cloudinary.com/sbmagar-media-storage/image/upload/v1/media/django-summernote/2022-02-14/4694a722-c6dc-447c-9f97-cabf2bc89ed7_fwggor)  \r\n\r\n*   From Configuration > Network Settings:\r\n    \r\n    *   Change Hostname or IP Address to _**[vpn.yourdomain.com](http://vpn.yourdomain.com)**_ and click save settings.\r\n    *   Now click on Update running server.\r\n    \r\n    ![](https://res.cloudinary.com/sbmagar-media-storage/image/upload/v1/media/django-summernote/2022-02-14/79ec66c7-fc3d-47ba-9c4b-8e1f17d890e4_cdgqlt)  \r\n    \r\n\r\nAnd you have successfully set up a custom domain. Visit [**_https://vpn.yourdomain.com:943/admin_**](https://vpn.yourdomain.com:943/admin***) it will work perfectly!  \r\n  \r\n\r\nSSL Set-Up:\r\n-----------\r\n\r\nAs there is no SSL configured your server is not trusted by browsers. In this section, we’re going to use Certbot to install SSL certificate. For this:\r\n\r\n*   SSH to your VPN server and type the following commands:\r\n\t\r\n\t\tsudo apt-get update\r\n\t\tsudo apt-get install software-properties-common\r\n\t\tsudo add-apt-repository universe\r\n\t\tsudo add-apt-repository ppa:certbot/certbot\r\n\t\tsudo apt-get update\r\n\t\tsudo apt-get install -y certbot\r\n    \r\n\r\nTo install Certbot, open port 80 temporarily on the security group of your OpenVPN server (Certbot will verify the server and domain).\r\n\r\n*   Go to AWS console, choose openVPN security group > inbound rules and add HTTP 80 rule with source 0.0.0.0/0 to access port 80 traffic.\r\n*   SSH into openVPN server again and type the following command:\r\n\r\n    sudo certbot certonly --standalone\r\n    \r\n\r\nFollow no. of questions with answering them and use domain as [_**vpn.yourdomain.com**_](http://vpn.yourdomain.com). It will verify using port 80.\r\n\r\n\t\topenvpnas@10.0.101.94:~$ sudo certbot certonly --standalone\r\n\t\tSaving debug log to /var/log/letsencrypt/letsencrypt.log\r\n\t\tPlugins selected: Authenticator standalone, Installer None\r\n\t\tEnter email address (used for urgent renewal and security notices) (Enter 'c' to cancel): support@yourdomain.com\r\n\r\n\t\t- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\r\n\t\tPlease read the Terms of Service at\r\n\t\t<https://letsencrypt.org/documents/LE-SA-v1.2-November-15-2017.pdf>. You must\r\n\t\tagree in order to register with the ACME server at\r\n\t\t<https://acme-v02.api.letsencrypt.org/directory>\r\n\t\t- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\r\n\t\t(A)gree/(C)ancel: A\r\n\r\n\t\t- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\r\n\t\tWould you be willing to share your email address with the Electronic Frontier\r\n\t\tFoundation, a founding partner of the Let's Encrypt project and the non-profit\r\n\t\torganization that develops Certbot? We'd like to send you email about our work\r\n\t\tencrypting the web, EFF news, campaigns, and ways to support digital freedom.\r\n\t\t- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\r\n\t\t(Y)es/(N)o: N\r\n\t\tPlease enter in your domain name(s) (comma and/or space separated)  (Enter 'c'\r\n\t\tto cancel): vpn.yourdoman.com\r\n\t\tObtaining a new certificate\r\n\t\tPerforming the following challenges:\r\n\t\thttp-01 challenge for vpn.yourdoman.com\r\n\t\tWaiting for verification...\r\n\t\tCleaning up challenges\r\n\r\n\t\tIMPORTANT NOTES:\r\n\t\t - Congratulations! Your certificate and chain have been saved at:\r\n\t\t   /etc/letsencrypt/live/vpn.youdomain.com/fullchain.pem\r\n\t\t   Your key file has been saved at:\r\n\t\t   /etc/letsencrypt/live/vpn.youdomain.com/privkey.pem\r\n\t\t   Your cert will expire on 2022-04-14. To obtain a new or tweaked\r\n\t\t   version of this certificate in the future, simply run certbot\r\n\t\t   again. To non-interactively renew *all* of your certificates, run\r\n\t\t   \"certbot renew\"\r\n\t\t - If you like Certbot, please consider supporting our work by:\r\n    \r\n\r\nAfter this, you can remove HTTP port 80 rule as you don’t need it anymore.\r\n\r\nUse the following commands to show the text content of 2 files _**privkey.pem**_ and _**fullchain.pem,**_ and copy them manually and save them locally with the same filename: (make sure you replace [_**vpn.yourdomain.com**_](http://vpn.yourdomain.com) with the expected domain or IP)\r\n\r\n    cat /etc/letsencrypt/live/vpn.youdomain.com/fullchain.pem\r\n    cat /etc/letsencrypt/live/vpn.youdomain.com/privkey.pem\r\n    \r\n    \r\n\r\n### Configure SSL certificate to OpenVPN server:\r\n\r\n*   Visit **[https://vpn.yourdomain.com:943/admin](https://vpn.yourdomain.com:943/admin)** and login with admin credentials used earlier.\r\n*   Go to Configuration > Web Server:\r\n    *   Upload local _**fullchain.pem**_ for Certificate and local _**privkey.pem**_ for Private Key. Then click Validate.\r\n    *   Click on Save and Update existing server.\r\n\r\nHere we go, you have successfully set up SSL to your openVPN server.  \r\n  \r\n\r\n### Create New User:\r\n\r\nGo to VPN admin URL and from User Management panel:\r\n\r\n*   Go to User Permission, enter new username ‘clientuser’ (you can use any) and click More Settings and set new password.\r\n*   Click on Save Settings and Update existing server.  \r\n      \r\n\r\n### Login:\r\n\r\nNow, go to the client VPN URL(without /admin)([_**https://your.domain.com:943/**_](https://your.domain.com:943/***)) and log in with the credentials you set up earlier. You can download the client config file also. Or reset password and username from the admin panel.\r\n\r\nThat’s it!\r\n\r\nThank you!!", "publish": "2022-02-14T07:13:26Z", "created_on": "2022-02-14T07:25:16.057Z", "status": 1, "visit_num": 744, "keywords": "Python", "categories": [3]}}, {"model": "blogs.post", "pk": 9, "fields": {"title": "Gmail with Custom Domain using Cloudflare", "slug": "gmail-with-custom-domain-using-cloudflare", "author": ["sagar"], "updated_on": "2022-11-23T22:42:50.606Z", "short_desciption": "In this tutorial, we’ll set up Gmail with custom domain using cloudflare so that you can send/receive emails entirely for free.", "image": "media/images/Untitled_design_8_nmqx7w", "content": "If you have a personal/business website, creating a free custom domain email address is essential. However, most services charge a subscription fee for allowing you to host emails with your domain. Even google’s plan is not free at all like before.\r\n\r\nIn this tutorial, we’ll set up Gmail with custom domain so that you can send/receive emails entirely for free.\r\n\r\n## Prerequisites\r\n\r\n- Domain name (I have hosted the domain name on Cloudflare)\r\n- Regular Gmail Account\r\n\r\n## **Set Up Gmail with Custom Domain Email Address using Cloudflare**\r\n\r\nFirst, we need to create a custom email address using our email hosting (or domain hosting). E.g. `contact@yourdomain.com.np`. You can use free email forwarding services to create a custom email address.\r\n\r\nBut If you’re using Cloudflare as a DNS service, you can use their free email service which is currently a beta version.\r\n\r\nAs I’m using Cloudflare as a DNS service:\r\n\r\n### **1. Custom Email**\r\n\r\n- Go to **email** on the [Cloudflare dashboard](https://dash.cloudflare.com/) and **create address**.\r\n- Enter the custom email address you want to create.\r\n- **Add destination email address**, in my case I’ve added my Gmail address. (This means all emails to the custom email addresses will be forwarded to your main Gmail address)\r\n\r\nCloudflare will send a verification link to your destination email address. Verify the email address to activate the email routing.\r\n\r\n### **2. Add DNS Records**\r\n\r\nNow, after creating a custom email address and verifying the destination email address, you need to set up MX and TXT records to your DNS. This can be done automatically by clicking Add records automatically.\r\n\r\n![DNS Records](/media/editor/Selection_049_20220919063701630929.png \"DNS Records\")\r\n**Note: *if there are other MX records already configured in DNS, Cloudflare will ask you if you wish to delete them. If you don’t delete existing ones, email routing won’t be configured.***\r\n\r\n### **3. Test**\r\n\r\nSend an email from another mail address to the custom mail address you set up above. You will see that email to your main address (`my_account@gmail.com`).\r\n\r\n## **Send with custom email address in Gmail using SMTP (Gmail with custom domain)**\r\n\r\nYou have successfully set up a custom email and configured it to receive all emails sent to custom mail to your main Gmail address.\r\n\r\nIn this section, we’ll be configuring Gmail with custom domain so that we’ll be able to reply from your custom email domain.\r\n\r\n### **Step-1: Generate App Password**\r\n\r\n- Sign in to your [google account](https://myaccount.google.com/). Go to **Security** > **App passwords**\r\n\r\n![](/media/editor/lesssecureappgoogle_20220919063735637140.png)\r\nmyaccount.google.com\r\n\r\n- Enter your password and click **Next**.\r\n- Click on **Select app** and select **Other**\r\n\r\n![Gmail App Password](/media/editor/Selection_033_20220919070037630636.png \"Gmail App Password\")\r\n- Enter your app name whatever you want (in my case, I used ‘`contact@mydomain.com.np`’ as my app name) and click **Generate.** Copy or save the password generated. We’ll use this later.\r\n\r\n![](/media/editor/Selection_035_20220919070117278625.png)\r\nGo back to Gmail and follow the steps:\r\n\r\n### **Step-2: Configure Gmail SMTP Server**\r\n\r\n- **Gmail settings** > **Accounts and Import**\r\n- Click on **Add another email adddress**. Enter custom email address created before (`contact@yourdomain.com.np`). Uncheck **Treat as an alias** checkbox. Doing so will send all your emails using your Gmail address.\r\n\r\n![](/media/editor/Selection_028_20220919070147573517.png)\r\n- Go to **Next Step** and configure:\r\n    - **SMTP Server**: `smtp.gmail.com`\r\n    - **Username**: your full Gmail address (main Gmail address) (yourmail@gmail.com)\r\n    - **Password**: password generated in **step-1** (Important)\r\n    - **Port**: 587(TLS) or 465(SSL)\r\n\r\n![](/media/editor/Selection_029_20220919070254118605.png)\r\n- Click on **Save Changes**. Then a confirmation email will be sent to your mail address with a confirmation code. Enter that code and click Verify. Or you can click the link sent by mail.\r\n\r\n![](/media/editor/Selection_038_20220919070316775643.png)\r\nGmail verification\r\n\r\n![](/media/editor/Selection_039_20220919070334532641.png)\r\nYou have successfully verified your custom email address and setup with Gmail. You can send/reply with your custom domain using Gmail.\r\n\r\nFurther,\r\n\r\nYou can make the custom email address a default mailing address:\r\n\r\n![](/media/editor/Selection_042_20220919070352390895.png)\r\n### **Step-3: Test**\r\n\r\n![](/media/editor/Selection_046_20220919070430476149.png)\r\nIf everything works, you’re all done configuring Gmail with custom domain.\r\n\r\n## **Conclusion**\r\n\r\nIn this way, we have configured DNS and Gmail in a way so that emails sent to your domain email address will show up in your Gmail mailbox, and also you can send or reply from your custom domain email address.\r\n\r\nIf you still have questions about how to configure Gmail with custom domain name, ask us in the comments!", "publish": "2022-09-18T16:54:49Z", "created_on": "2022-09-18T17:09:23.771Z", "status": 1, "visit_num": 161, "keywords": "DevOps, Gmail, Cloudflare", "categories": [2]}}, {"model": "works.work", "pk": 1, "fields": {"title": "Django/Plotly - environmental sensors data handling", "slug": "djangoplotly-environmental-sensors-data-handling", "author": ["sagar"], "updated_on": "2022-11-21T14:11:27.798Z", "short_desciption": "Sensors data encoding-decoding, CRUD operations, and database managing socketing visualizing with Plotly-dash", "image": "media/images/plotly_millmz", "content": "Fully functional implementation of Plotly-Dash data visualizations tool with Django. (Map, sensors data CRUD, encode decode data from server, UI etc)\r\n\r\n**TASKS/ACHIEVEMENTS:**\r\n\r\n**1\\. Developed fully functioning ffmpeg/live555 RTSP protocol (\"Image process (CCTV, NVR) window app development\").**\r\n\r\n*   Link to demo source code: [https://github.com/SBMagar/ffmpeg\\_first](https://github.com/SBMagar/ffmpeg_first)\r\n\r\n**2. Developed Sensor Operator Server UI with Django (\"Black Ice Detection System\") as a team project.**\r\n\r\n**3. UDP Server, MariaDB for sensor database(\"Black Ice Detection System\"), worked on decoding of sensors input data.**\r\n\r\n*   Link to Demo source code: [https://github.com/SBMagar/IBZ\\_Networks](https://github.com/SBMagar/IBZ_Networks)[](https://github.com/SBMagar/IBZ_Networks)\r\n\r\n**4. Worked on basics of Web Scraping, Model Development, Data Visualization etc.**", "live": "Some snapshots of project during development:\r\n\r\n![](https://res.cloudinary.com/sbmagar-media-storage/image/upload/v1/media/django-summernote/2021-05-27/fa94a85f-3d82-47e6-a7f6-0f95ecc8e64a_qjo0o3)\r\n\r\n  \r\n\r\n![](https://res.cloudinary.com/sbmagar-media-storage/image/upload/v1/media/django-summernote/2021-08-25/2c37fc1f-f9f9-4f62-a81d-b16082a3fbe6_va5jf0)\r\n\r\n  \r\n\r\n![](https://res.cloudinary.com/sbmagar-media-storage/image/upload/v1/media/django-summernote/2021-08-25/2446634c-cd50-447a-85a4-c05841ac9821_yruzl9)", "downloadOrView": "Django based dynamic web application for Sensors data encoding-decoding, CRUD operations, and database managing socketing visualizing with Plotly-dash(Black-Ice Detection System)\r\n\r\nDemo version Source-Code: [https://github.com/SBMagar/IBZ\\_Networks](https://github.com/SBMagar/IBZ_Networks)", "created_on": "2021-05-26T13:07:43.120Z", "status": 1, "visit_num": 705, "categories": [1]}}, {"model": "works.work", "pk": 2, "fields": {"title": "AI Chatbot", "slug": "ai-chatbot", "author": ["sagar"], "updated_on": "2022-11-21T02:52:40.190Z", "short_desciption": "AI powered chatbot with RASA stack", "image": "media/images/volgai_chatbot3_wo0uii", "content": "\"Chatbot with RASA Stack\"\r\n=========================\r\n\r\nThe bot is still in the development phase.... (I'll publish the demo version soon... as of now you can talk to the official demo bot on Volgai website([https://volgai.com](https://www.blogger.com/blog/post/edit/2875741694909600015/7287179243067575496#))\r\n\r\n  \r\n\r\nBot is developed using Python RASA-Stack(Docker, docker-compose, supervisord, Nginx, RabbitMQ, Redis, PostgreSQL etc.)", "live": "![](https://1.bp.blogspot.com/-oEkoAQXL70s/YIbzuJb_osI/AAAAAAAAKic/AjZdrf-_TkslbTUjuuWpviGE7UKWeTglwCNcBGAsYHQ/s0/IMG_20210426_221854.jpg)\r\n\r\n  \r\n \r\n\r\n![](https://1.bp.blogspot.com/-GZBTo7h5yB4/YIbzs7phPlI/AAAAAAAAKiY/JupIsdOg_LwPzjHtwjFKW6R3DfPmeOnSwCNcBGAsYHQ/s0/IMG_20210426_221433.jpg)\r\n\r\n  \r\n\r\nwith main UI:\r\n\r\n  \r\n\r\n![](https://res.cloudinary.com/sbmagar-media-storage/image/upload/v1/media/django-summernote/2021-05-27/8bb92e4d-ccac-49ee-bea8-aa11edcfcb6a_ounozt)", "downloadOrView": "Python RASA based NLP-AI chatbot assistant.", "created_on": "2021-05-26T13:21:03.934Z", "status": 1, "visit_num": 691, "categories": [2]}}, {"model": "works.work", "pk": 3, "fields": {"title": "Text-to-Image Synthesis using GAN", "slug": "text-image-synthesis", "author": ["sagar"], "updated_on": "2022-11-22T22:28:52.844Z", "short_desciption": "Image Synthesis using dcGAN & stackGAN hybrid", "image": "media/images/text-to-image_ee8pxu", "content": "GAN … (with source code will update soon…)\r\n\r\nGeneration of Plausible image from text description as a input prompt. And input image is noise.\r\n\r\n![](https://res.cloudinary.com/sbmagar-media-storage/image/upload/v1/media/django-summernote/2021-08-25/f9932f2b-a2c4-4e80-93d0-691edf030145_gvpn5t) to ![](https://res.cloudinary.com/sbmagar-media-storage/image/upload/v1/media/django-summernote/2021-08-25/a641a9d3-789a-46bb-a0c8-c42203c67385_yrkby0)  \r\n\r\n  \r\n\r\nImage dataset used: [Oxford 102 flowers](https://www.robots.ox.ac.uk/~vgg/data/flowers/102/)\r\n\r\n(Python, TensorFlow, DCGAN, RNN, CNN, LSTM, ReLu,)\r\n\r\nTASKS/ACHIEVEMENTS:\r\n\r\n**1\\. GAN neural networks (Deep Learning)**\r\n\r\n*   Generator, Discriminator concepts\r\n*   Text embeddings for visual attributes\r\n*   Interpolation of text embeddings\r\n*   Refinements, Loss calculations\r\n\r\n  \r\n\r\nObjective:\r\n\r\n*   To develop a model to generate plausible images of flower from the detailed text descriptions.", "live": "![](https://lh6.googleusercontent.com/V8JDydLBTvBWdhfy8FmWRDr4oZkRsH4p4GuSIL27KVkaOW6Nrw9u3wMzkWe0XjwWQH2n1Z_AA_OzBN8eCG3lkTDwJUwU7bqGFC8P2D3b1w1UBGZ4XQmnXh5d564Ky286TE8GQQlQ)\r\n\r\n![](https://lh3.googleusercontent.com/aM-rU5M3q413bPcmBIaUhdvXqOI8C02lKb8jB3a6pCpcD2GcEjVNhNFTb8qXgRuDgVboJFAJKDHkXPle2pPLMfXIYYkG98fptYZx2SodtBj2N_DGIywydLLyh4pjhh73Qe4KGDsx)\r\n\r\n![](https://lh3.googleusercontent.com/-M91kp5XrNUGl55B-_PR7LN-pBgq2RIX3PDc65emlWLL22X9ynCcivjDSUwTcg4o9-7QMVMXJsqSo-wTZGAk20AeZ89cJumWexIiU3Gck0mr7dqpf8bMadc5nNVFP3GpkLrPlcii)\r\n\r\nGenerated Image:\r\n\r\nText: “the petals on this flower are yellow with a red center and pink leafs”  \r\n\r\n![https://lh6.googleusercontent.com/9LBuU4nGdArbKZVU8jvfAdm7K5TPBzHwa14LxNAbMhapTjXzKMRmAAk8r67FQuahoYrAxEphdz2kjEShoDnpx7gsMApVnr7JwILpibJj0RND2SJ-fiDUPjrvEzsdo-fQvNQChD0T](https://lh3.googleusercontent.com/JlEpq-oREeC5p9WjVtyTKGNY5YcF5wJc1nWVO9cYFSRj8LneTagMNvqF3_19UVUdVPUlDvWCQ4z8gwMV08zYW-kUfj9Z_FnpCCS31To34-XoXU6y3gIMWrRg0e9UWEFQlEp3410W)  \r\n\r\n![https://lh6.googleusercontent.com/fCHVy_Zn6ZuTLc5ix2nta7Wm1Gh2xVFDCi12cpXrXIFMuqBwprZlbJlpCmBgoTY2w0A1L95mLLKlDV2Cl3hPfKhC-KUlppwB16siPuOUN5zm-hWdwBZGczdDpgzhl_CJ-PdulJd_](https://lh6.googleusercontent.com/ymHFZjUF0GGwQtToY_Qz90YyDHY6o-OsdcD8R1u2z1RZSmIa5W2REOZ1eMl69hvFwX3sMss8nJmXCi1mMEz3VZUVPsUVUHBh01cZbJEUAzbM7DRjqDBnLuFfWfz2PXU-Hfw6jmn_)", "downloadOrView": "Generative Adversarial Neural networks \r\n\r\n\\- Output as plausible Image of flower when text description of flower is given as input.", "created_on": "2021-05-26T13:31:18.484Z", "status": 1, "visit_num": 724, "categories": [2]}}, {"model": "works.work", "pk": 4, "fields": {"title": "Scrapy - Web Scraping with Python", "slug": "scrapy-web-scraping-python", "author": ["sagar"], "updated_on": "2022-11-22T15:32:52.856Z", "short_desciption": "Scrapy project with ReCAPTCHA bypass", "image": "media/images/Screenshot_from_2021-02-24_21-53-17_mljamd", "content": "Link for model training and testing source code:\r\n\r\n[https://colab.research.google.com/drive/1B9qCVVQd2setNu26neWYL2sv\\_dzDj9mV?usp=sharing](https://colab.research.google.com/drive/1B9qCVVQd2setNu26neWYL2sv_dzDj9mV?usp=sharing)  \r\n\r\nA project to scrape some portion of Data from the forum(RaidForums) with Python SCRAPY spiders bypassing ReCaptcha and storing it to PostgreSQL database. (used scrapper-API as a captcha, proxy bypass) SQLAlchemy as ORM for PostgreSQL - Python.", "live": "![](https://res.cloudinary.com/sbmagar-media-storage/image/upload/v1/media/django-summernote/2021-05-27/9a50b7f3-7022-44c9-a6bb-996f1756e965_looegr)  \r\n\r\n  \r\n\r\n![](https://res.cloudinary.com/sbmagar-media-storage/image/upload/v1/media/django-summernote/2021-05-27/d33ad5f7-1985-4fd1-9731-6904a5aecf7b_tzqp1i)  \r\n\r\n  \r\n\r\n![](https://res.cloudinary.com/sbmagar-media-storage/image/upload/v1/media/django-summernote/2021-05-27/27a8f61e-b549-4577-bbb7-b0fa9136fd43_gcny1c)", "downloadOrView": "Demo Source-Code: [https://github.com/SBMagar/raidfscrape/tree/master](https://github.com/SBMagar/raidfscrape/tree/master)", "created_on": "2021-05-26T13:58:43.843Z", "status": 1, "visit_num": 1411, "categories": [5]}}, {"model": "works.work", "pk": 5, "fields": {"title": "Object Detection (IBM cloud)", "slug": "object-detectionibm-annotations", "author": ["sagar"], "updated_on": "2022-11-22T15:33:24.195Z", "short_desciption": "Object detection demo project", "image": "media/images/Screenshot_from_2021-07-18_05-39-13_oa8sac", "content": "Link for model training and testing source code:\r\n\r\n[https://colab.research.google.com/drive/1B9qCVVQd2setNu26neWYL2sv\\_dzDj9mV?usp=sharing](https://colab.research.google.com/drive/1B9qCVVQd2setNu26neWYL2sv_dzDj9mV?usp=sharing)", "live": "https://youtu.be/sG6GUlHLF64", "downloadOrView": "", "created_on": "2021-07-17T23:49:08.831Z", "status": 1, "visit_num": 1037, "categories": [2]}}, {"model": "works.work", "pk": 6, "fields": {"title": "RASA Chatbot (VolgAI, Personal FAQs)", "slug": "rasa-chatbot", "author": ["sagar"], "updated_on": "2022-11-22T15:33:55.256Z", "short_desciption": "NLP AI Powered chatbot", "image": "media/images/chatbot-demo1_ifbsbo", "content": "# Links to personal FAQ chatbot:\r\n\r\npersonal\\_bot: [Personal_Chatbot](https://sbmagar.github.io/) ….\r\n\r\nsource code : [GitHub](https://github.com/SBMagar/personal_chatbot)\r\n\r\n  \r\n\r\nBot is developed using Python RASA-Stack(Docker, docker-compose, supervisord, Nginx, RabbitMQ, Redis, PostgreSQL etc.)", "live": "An AI powered Information Retrieval chatbot developed using the RASA stack.(Python, JavaScript, JQuery, HTML/CSS, YAML, Docker, docker-compose, supervisord, Nginx, RabbitMQ, Redis, PostgreSQL etc.)\r\n\r\n**Tasks/Achievements:**\r\n\r\n**Overall Result:**\r\n\r\n*   ﻿Chatbot Development from scratch with RASA Stack(NLP).\r\n*   Model Optimization, pipeline configurations, rasa-x integration.\r\n*   STT intgration with rasa chatbot.\r\n*   chatbot frontend development.\r\n*   Docker/docker-compose deployment, supervisord, nginx, postgres, rabbitmq, etc. for deployment.\r\n\r\n**Designing and concepts:**\r\n\r\n*   ﻿Define chatbot personality\r\n*   User intent, Chatbot action (interaction) design\r\n*   User testing with GUI\r\n*   Concepts of RASA core, RASA NLU, Domain, Stories, NLU Data, etc.  \r\n    \r\n\r\nBuilding and working:\r\n\r\n*   ﻿Understanding of user input, NLP\r\n*   Natural Language Understanding(NLU)  \r\n    \r\n*   Different approaches for the response that the chatbot will generate\r\n*   Intent and Entity extraction, slots using, LSTM-RNN, GRU cell\r\n*   Contextual dialogue handling with deep learning", "downloadOrView": "For demo project: [https://sbmagar.github.io](https://sbmagar.github.io)[](https://sbmagar.github.io) (Due to server limit, might not work at the time)\r\n\r\nPlease do visit, [https://volgai.com](https://volgai.com) for official chatbot.\r\n\r\n![](https://res.cloudinary.com/sbmagar-media-storage/image/upload/v1/media/django-summernote/2021-08-25/5adfb73a-3a2c-4956-8762-90cdb6051e9f_migdu1)  \r\n\r\n![](https://res.cloudinary.com/sbmagar-media-storage/image/upload/v1/media/django-summernote/2021-08-25/9c2816b6-2c31-44a2-9af4-d3632f6e70c8_tacaug)![](https://res.cloudinary.com/sbmagar-media-storage/image/upload/v1/media/django-summernote/2021-08-25/c0e3a644-44ec-4b0d-bf9c-47790a548fcc_wygzp2)", "created_on": "2021-08-02T18:04:30.740Z", "status": 1, "visit_num": 1214, "categories": [2]}}, {"model": "admin.logentry", "pk": 1, "fields": {"action_time": "2021-05-26T09:10:53.876Z", "user": ["sagar"], "content_type": ["blogs", "category_post"], "object_id": "1", "object_repr": "Category_post object (1)", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 2, "fields": {"action_time": "2021-05-26T09:11:24.710Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "1", "object_repr": "AI Chatbot", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 3, "fields": {"action_time": "2021-05-26T09:33:21.377Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "1", "object_repr": "AI Chatbot", "action_flag": 2, "change_message": "[]"}}, {"model": "admin.logentry", "pk": 4, "fields": {"action_time": "2021-05-26T09:34:34.495Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "1", "object_repr": "AI Chatbot", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 5, "fields": {"action_time": "2021-05-26T12:44:36.639Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "2", "object_repr": "Nepal - Covid-19 Prediction models using different ML algorithms", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 6, "fields": {"action_time": "2021-05-26T12:51:56.635Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "3", "object_repr": "Simple Amazon Lex Weather Chatbot", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 7, "fields": {"action_time": "2021-05-26T12:52:56.542Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "1", "object_repr": "AI Chatbot", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\"]}}]"}}, {"model": "admin.logentry", "pk": 8, "fields": {"action_time": "2021-05-26T13:06:15.373Z", "user": ["sagar"], "content_type": ["works", "category_work"], "object_id": "1", "object_repr": "Category_work object (1)", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 9, "fields": {"action_time": "2021-05-26T13:07:43.131Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "1", "object_repr": "Django/Plotly - environmental sensors data handling", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 10, "fields": {"action_time": "2021-05-26T13:12:20.702Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "1", "object_repr": "Django/Plotly - environmental sensors data handling", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"DownloadOrView\"]}}]"}}, {"model": "admin.logentry", "pk": 11, "fields": {"action_time": "2021-05-26T13:20:52.006Z", "user": ["sagar"], "content_type": ["works", "category_work"], "object_id": "2", "object_repr": "Category_work object (2)", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 12, "fields": {"action_time": "2021-05-26T13:21:03.945Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "2", "object_repr": "AI Chatbot", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 13, "fields": {"action_time": "2021-05-26T13:31:18.511Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "3", "object_repr": "Text-to-Image Synthesis", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 14, "fields": {"action_time": "2021-05-26T13:38:27.213Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "3", "object_repr": "Text-to-Image Synthesis", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\", \"Live\"]}}]"}}, {"model": "admin.logentry", "pk": 15, "fields": {"action_time": "2021-05-26T13:41:02.285Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "3", "object_repr": "Text-to-Image Synthesis", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 16, "fields": {"action_time": "2021-05-26T13:58:27.016Z", "user": ["sagar"], "content_type": ["works", "category_work"], "object_id": "3", "object_repr": "Category_work object (3)", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 17, "fields": {"action_time": "2021-05-26T13:58:43.852Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "4", "object_repr": "Scrapy - Web Scraping with Python", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 18, "fields": {"action_time": "2021-05-26T13:59:31.202Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "2", "object_repr": "AI Chatbot", "action_flag": 2, "change_message": "[]"}}, {"model": "admin.logentry", "pk": 19, "fields": {"action_time": "2021-05-26T14:21:25.407Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "1", "object_repr": "Django/Plotly - environmental sensors data handling", "action_flag": 2, "change_message": "[]"}}, {"model": "admin.logentry", "pk": 20, "fields": {"action_time": "2021-05-26T14:23:20.656Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "4", "object_repr": "Scrapy - Web Scraping with Python", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\", \"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 21, "fields": {"action_time": "2021-05-26T14:24:57.205Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "3", "object_repr": "Text-to-Image Synthesis", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\", \"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 22, "fields": {"action_time": "2021-05-26T14:27:15.045Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "1", "object_repr": "Django/Plotly - environmental sensors data handling", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\", \"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 23, "fields": {"action_time": "2021-05-26T14:28:08.140Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "2", "object_repr": "AI Chatbot", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\", \"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 24, "fields": {"action_time": "2021-05-26T14:31:20.859Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "4", "object_repr": "Scrapy - Web Scraping with Python", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Short desciption\", \"Live\"]}}]"}}, {"model": "admin.logentry", "pk": 25, "fields": {"action_time": "2021-05-26T14:31:53.644Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "3", "object_repr": "Text-to-Image Synthesis", "action_flag": 2, "change_message": "[]"}}, {"model": "admin.logentry", "pk": 26, "fields": {"action_time": "2021-05-27T07:28:55.595Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "1", "object_repr": "Django/Plotly - environmental sensors data handling", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\", \"Content\", \"Live\", \"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 27, "fields": {"action_time": "2021-05-27T14:03:29.962Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "4", "object_repr": "Scrapy - Web Scraping with Python", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\", \"Live\"]}}]"}}, {"model": "admin.logentry", "pk": 28, "fields": {"action_time": "2021-05-27T15:49:23.829Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "4", "object_repr": "Scrapy - Web Scraping with Python", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\", \"Live\"]}}]"}}, {"model": "admin.logentry", "pk": 29, "fields": {"action_time": "2021-05-27T16:21:40.225Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "4", "object_repr": "Scrapy - Web Scraping with Python", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\", \"Live\"]}}]"}}, {"model": "admin.logentry", "pk": 30, "fields": {"action_time": "2021-05-27T17:11:43.759Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "4", "object_repr": "Scrapy - Web Scraping with Python", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\", \"Live\"]}}]"}}, {"model": "admin.logentry", "pk": 31, "fields": {"action_time": "2021-05-27T17:12:39.801Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "4", "object_repr": "Scrapy - Web Scraping with Python", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\"]}}]"}}, {"model": "admin.logentry", "pk": 32, "fields": {"action_time": "2021-05-27T17:18:55.128Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "3", "object_repr": "Text-to-Image Synthesis", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\"]}}]"}}, {"model": "admin.logentry", "pk": 33, "fields": {"action_time": "2021-05-27T17:35:22.558Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "2", "object_repr": "AI Chatbot", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\", \"Live\"]}}]"}}, {"model": "admin.logentry", "pk": 34, "fields": {"action_time": "2021-05-27T17:36:13.542Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "2", "object_repr": "AI Chatbot", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\"]}}]"}}, {"model": "admin.logentry", "pk": 35, "fields": {"action_time": "2021-05-27T17:36:50.187Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "1", "object_repr": "Django/Plotly - environmental sensors data handling", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\"]}}]"}}, {"model": "admin.logentry", "pk": 36, "fields": {"action_time": "2021-05-27T23:02:32.079Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "4", "object_repr": "Scrapy - Web Scraping with Python", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\", \"Live\", \"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 37, "fields": {"action_time": "2021-05-27T23:05:38.072Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "3", "object_repr": "Text-to-Image Synthesis", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\", \"DownloadOrView\"]}}]"}}, {"model": "admin.logentry", "pk": 38, "fields": {"action_time": "2021-05-27T23:06:36.915Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "3", "object_repr": "Text-to-Image Synthesis", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"DownloadOrView\"]}}]"}}, {"model": "admin.logentry", "pk": 39, "fields": {"action_time": "2021-05-27T23:07:49.585Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "2", "object_repr": "AI Chatbot", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\", \"Live\"]}}]"}}, {"model": "admin.logentry", "pk": 40, "fields": {"action_time": "2021-05-27T23:08:35.585Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "1", "object_repr": "Django/Plotly - environmental sensors data handling", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\", \"Live\"]}}]"}}, {"model": "admin.logentry", "pk": 41, "fields": {"action_time": "2021-06-03T23:34:39.413Z", "user": ["sagar"], "content_type": ["blogs", "category_post"], "object_id": "2", "object_repr": "Category_post object (2)", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 42, "fields": {"action_time": "2021-06-03T23:34:58.200Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "4", "object_repr": "Django, Postgres, Gunicorn, Nginx with Docker", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 43, "fields": {"action_time": "2021-06-03T23:44:44.236Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "4", "object_repr": "Django, Postgres, Gunicorn, Nginx with Docker", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\", \"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 44, "fields": {"action_time": "2021-06-03T23:45:44.305Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "4", "object_repr": "Django, Postgres, Gunicorn, Nginx with Docker (Part-1)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Title\", \"Image\"]}}]"}}, {"model": "admin.logentry", "pk": 45, "fields": {"action_time": "2021-06-04T00:26:56.154Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "4", "object_repr": "Django, Postgres, Gunicorn, Nginx with Docker (Part-1)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\", \"Content\", \"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 46, "fields": {"action_time": "2021-06-04T00:29:01.659Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "4", "object_repr": "Django, Postgres, Gunicorn, Nginx with Docker (Part-1)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\", \"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 47, "fields": {"action_time": "2021-06-04T00:29:58.694Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "4", "object_repr": "Django, Postgres, Gunicorn, Nginx with Docker (Part-1)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\", \"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 48, "fields": {"action_time": "2021-06-04T12:31:49.784Z", "user": ["sagar"], "content_type": ["blogs", "category_post"], "object_id": "2", "object_repr": "Category_post object (2)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Name\"]}}]"}}, {"model": "admin.logentry", "pk": 49, "fields": {"action_time": "2021-06-04T12:33:24.104Z", "user": ["sagar"], "content_type": ["blogs", "category_post"], "object_id": "1", "object_repr": "Category_post object (1)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Name\"]}}]"}}, {"model": "admin.logentry", "pk": 50, "fields": {"action_time": "2021-06-04T12:35:00.603Z", "user": ["sagar"], "content_type": ["works", "category_work"], "object_id": "1", "object_repr": "Category_work object (1)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Name\"]}}]"}}, {"model": "admin.logentry", "pk": 51, "fields": {"action_time": "2021-06-04T12:36:25.790Z", "user": ["sagar"], "content_type": ["works", "category_work"], "object_id": "2", "object_repr": "Category_work object (2)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Name\", \"Slug\"]}}]"}}, {"model": "admin.logentry", "pk": 52, "fields": {"action_time": "2021-06-04T12:36:43.513Z", "user": ["sagar"], "content_type": ["works", "category_work"], "object_id": "3", "object_repr": "Category_work object (3)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Name\"]}}]"}}, {"model": "admin.logentry", "pk": 53, "fields": {"action_time": "2021-06-04T12:38:16.443Z", "user": ["sagar"], "content_type": ["works", "category_work"], "object_id": "4", "object_repr": "Category_work object (4)", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 54, "fields": {"action_time": "2021-06-04T13:45:38.178Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "5", "object_repr": "Django, Postgres, Gunicorn, Nginx with Docker (Part-2)", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 55, "fields": {"action_time": "2021-06-04T13:51:04.381Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "5", "object_repr": "Django, Postgres, Gunicorn, Nginx with Docker (Part-2)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 56, "fields": {"action_time": "2021-06-04T13:57:26.578Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "4", "object_repr": "Django, Postgres, Gunicorn, Nginx with Docker (Part-1)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 57, "fields": {"action_time": "2021-06-04T14:09:12.954Z", "user": ["sagar"], "content_type": ["blogs", "comment"], "object_id": "1", "object_repr": "Comment by Joseph", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 58, "fields": {"action_time": "2021-07-17T23:49:08.862Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "5", "object_repr": "Object Detection(IBM cloud annotations)", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 59, "fields": {"action_time": "2021-07-17T23:51:42.485Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "5", "object_repr": "Object Detection(IBM cloud annotations)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\"]}}]"}}, {"model": "admin.logentry", "pk": 60, "fields": {"action_time": "2021-07-17T23:52:31.707Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "5", "object_repr": "Object Detection(IBM cloud annotations)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Categories\"]}}]"}}, {"model": "admin.logentry", "pk": 61, "fields": {"action_time": "2021-07-17T23:54:39.226Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "5", "object_repr": "Object Detection(IBM cloud annotations)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\"]}}]"}}, {"model": "admin.logentry", "pk": 62, "fields": {"action_time": "2021-07-17T23:56:33.214Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "5", "object_repr": "Object Detection(IBM cloud annotations)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 63, "fields": {"action_time": "2021-07-18T12:24:24.022Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "5", "object_repr": "Django, Postgres, Gunicorn, Nginx with Docker (Part-2)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 64, "fields": {"action_time": "2021-07-18T12:24:43.842Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "4", "object_repr": "Django, Postgres, Gunicorn, Nginx with Docker (Part-1)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 65, "fields": {"action_time": "2021-07-18T12:25:04.277Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "3", "object_repr": "Simple Amazon Lex Weather Chatbot", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 66, "fields": {"action_time": "2021-07-18T12:25:20.874Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "2", "object_repr": "Nepal - Covid-19 Prediction models using different ML algorithms", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 67, "fields": {"action_time": "2021-07-18T12:25:39.919Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "1", "object_repr": "AI Chatbot", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 68, "fields": {"action_time": "2021-07-18T12:26:25.669Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "4", "object_repr": "Scrapy - Web Scraping with Python", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 69, "fields": {"action_time": "2021-07-18T12:26:44.013Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "3", "object_repr": "Text-to-Image Synthesis", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 70, "fields": {"action_time": "2021-07-18T12:27:01.357Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "2", "object_repr": "AI Chatbot", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 71, "fields": {"action_time": "2021-07-18T12:27:16.174Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "1", "object_repr": "Django/Plotly - environmental sensors data handling", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 72, "fields": {"action_time": "2021-07-18T12:27:28.089Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "5", "object_repr": "Object Detection(IBM cloud annotations)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 73, "fields": {"action_time": "2021-07-28T21:22:58.928Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "4", "object_repr": "Django, Postgres, Gunicorn, Nginx with Docker (Part-1)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\", \"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 74, "fields": {"action_time": "2021-08-02T15:46:51.215Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "5", "object_repr": "Object Detection(IBM cloud annotations)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 75, "fields": {"action_time": "2021-08-02T15:47:06.562Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "4", "object_repr": "Scrapy - Web Scraping with Python", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 76, "fields": {"action_time": "2021-08-02T15:47:27.364Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "3", "object_repr": "Text-to-Image Synthesis", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 77, "fields": {"action_time": "2021-08-02T15:47:47.106Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "2", "object_repr": "AI Chatbot", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 78, "fields": {"action_time": "2021-08-02T15:48:07.118Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "1", "object_repr": "Django/Plotly - environmental sensors data handling", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 79, "fields": {"action_time": "2021-08-02T15:48:35.117Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "5", "object_repr": "Django, Postgres, Gunicorn, Nginx with Docker (Part-2)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 80, "fields": {"action_time": "2021-08-02T15:48:49.358Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "4", "object_repr": "Django, Postgres, Gunicorn, Nginx with Docker (Part-1)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 81, "fields": {"action_time": "2021-08-02T15:49:08.136Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "3", "object_repr": "Simple Amazon Lex Weather Chatbot", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 82, "fields": {"action_time": "2021-08-02T15:49:31.898Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "2", "object_repr": "Nepal - Covid-19 Prediction models using different ML algorithms", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 83, "fields": {"action_time": "2021-08-02T15:49:56.729Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "1", "object_repr": "AI Chatbot", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 84, "fields": {"action_time": "2021-08-02T18:00:20.936Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "1", "object_repr": "AI Chatbot", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 85, "fields": {"action_time": "2021-08-02T18:04:30.784Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "6", "object_repr": "RASA Chatbot", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 86, "fields": {"action_time": "2021-08-02T18:05:58.573Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "6", "object_repr": "RASA Chatbot", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\", \"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 87, "fields": {"action_time": "2021-08-02T18:07:21.545Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "5", "object_repr": "Object Detection(IBM annotations)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Title\", \"Slug\"]}}]"}}, {"model": "admin.logentry", "pk": 88, "fields": {"action_time": "2021-08-02T18:08:04.258Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "5", "object_repr": "Object Detection (IBM cloud)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Title\"]}}]"}}, {"model": "admin.logentry", "pk": 89, "fields": {"action_time": "2021-08-02T18:35:24.863Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "6", "object_repr": "RASA Chatbot", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Status\"]}}]"}}, {"model": "admin.logentry", "pk": 90, "fields": {"action_time": "2021-08-08T13:06:37.698Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "6", "object_repr": "RASA Chatbot", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Status\", \"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 91, "fields": {"action_time": "2021-08-15T21:31:31.469Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "6", "object_repr": "GAN(VQGAN)  + CLIP Architecture", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 92, "fields": {"action_time": "2021-08-15T21:39:58.367Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "6", "object_repr": "GAN(VQGAN)  + CLIP Architecture", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 93, "fields": {"action_time": "2021-08-15T21:47:11.480Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "6", "object_repr": "GAN(VQGAN)  + CLIP Architecture", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\", \"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 94, "fields": {"action_time": "2021-08-16T14:21:08.525Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "3", "object_repr": "Simple Amazon Lex Weather Chatbot", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\", \"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 95, "fields": {"action_time": "2021-08-16T14:23:57.160Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "2", "object_repr": "Nepal - Covid-19 Prediction models using different ML algorithms", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\", \"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 96, "fields": {"action_time": "2021-08-16T14:26:46.573Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "1", "object_repr": "AI Chatbot", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\", \"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 97, "fields": {"action_time": "2021-08-16T21:10:05.465Z", "user": ["sagar"], "content_type": ["auth", "user"], "object_id": "1", "object_repr": "sagar", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"First name\", \"Last name\"]}}]"}}, {"model": "admin.logentry", "pk": 98, "fields": {"action_time": "2021-08-16T21:11:40.945Z", "user": ["sagar"], "content_type": ["auth", "user"], "object_id": "1", "object_repr": "sagar", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Last name\"]}}]"}}, {"model": "admin.logentry", "pk": 99, "fields": {"action_time": "2021-08-17T07:31:04.203Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "6", "object_repr": "GAN(VQGAN)  + CLIP Architecture", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\", \"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 100, "fields": {"action_time": "2021-08-25T19:35:18.974Z", "user": ["sagar"], "content_type": ["works", "category_work"], "object_id": "5", "object_repr": "Category_work object (5)", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 101, "fields": {"action_time": "2021-08-25T19:58:34.041Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "4", "object_repr": "Scrapy - Web Scraping with Python", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Categories\"]}}]"}}, {"model": "admin.logentry", "pk": 102, "fields": {"action_time": "2021-08-25T20:03:50.623Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "4", "object_repr": "Scrapy - Web Scraping with Python", "action_flag": 2, "change_message": "[]"}}, {"model": "admin.logentry", "pk": 103, "fields": {"action_time": "2021-08-25T20:06:50.990Z", "user": ["sagar"], "content_type": ["works", "category_work"], "object_id": "5", "object_repr": "Category_work object (5)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Name\"]}}]"}}, {"model": "admin.logentry", "pk": 104, "fields": {"action_time": "2021-08-25T21:07:52.128Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "6", "object_repr": "RASA Chatbot (VolgAI, Personal FAQs)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Title\", \"DownloadOrView\", \"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 105, "fields": {"action_time": "2021-08-25T21:12:41.286Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "6", "object_repr": "RASA Chatbot (VolgAI, Personal FAQs)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\", \"Live\", \"DownloadOrView\", \"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 106, "fields": {"action_time": "2021-08-25T21:17:36.237Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "6", "object_repr": "RASA Chatbot (VolgAI, Personal FAQs)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\", \"Live\"]}}]"}}, {"model": "admin.logentry", "pk": 107, "fields": {"action_time": "2021-08-25T21:20:33.341Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "6", "object_repr": "RASA Chatbot (VolgAI, Personal FAQs)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 108, "fields": {"action_time": "2021-08-25T21:33:58.150Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "1", "object_repr": "Django/Plotly - environmental sensors data handling", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Live\", \"DownloadOrView\", \"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 109, "fields": {"action_time": "2021-08-25T21:47:46.043Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "3", "object_repr": "Text-to-Image Synthesis", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"DownloadOrView\"]}}]"}}, {"model": "admin.logentry", "pk": 110, "fields": {"action_time": "2021-08-25T21:56:02.382Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "3", "object_repr": "Text-to-Image Synthesis", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"DownloadOrView\"]}}]"}}, {"model": "admin.logentry", "pk": 111, "fields": {"action_time": "2021-08-25T21:56:44.379Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "3", "object_repr": "Text-to-Image Synthesis using GAN", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Title\"]}}]"}}, {"model": "admin.logentry", "pk": 112, "fields": {"action_time": "2021-08-25T22:00:01.702Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "6", "object_repr": "RASA Chatbot (VolgAI, Personal FAQs)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"DownloadOrView\"]}}]"}}, {"model": "admin.logentry", "pk": 113, "fields": {"action_time": "2022-01-25T20:52:50.019Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "6", "object_repr": "GAN(VQGAN)  + CLIP Architecture", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Tags\"]}}]"}}, {"model": "admin.logentry", "pk": 114, "fields": {"action_time": "2022-01-25T20:53:43.745Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "4", "object_repr": "Django, Postgres, Gunicorn, Nginx with Docker (Part-1)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Tags\"]}}]"}}, {"model": "admin.logentry", "pk": 115, "fields": {"action_time": "2022-02-09T09:31:54.996Z", "user": ["sagar"], "content_type": ["blogs", "category_post"], "object_id": "3", "object_repr": "Category_post object (3)", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 116, "fields": {"action_time": "2022-02-09T09:32:53.851Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "7", "object_repr": "Free Certbot-SSL with Nginx (HTTPS setup)", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 117, "fields": {"action_time": "2022-02-09T09:35:14.604Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "7", "object_repr": "Free Certbot-SSL with Nginx (HTTPS setup)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Short desciption\"]}}]"}}, {"model": "admin.logentry", "pk": 118, "fields": {"action_time": "2022-02-09T11:03:57.379Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "5", "object_repr": "Django, Postgres, Gunicorn, Nginx with Docker (Part-2)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Tags\"]}}]"}}, {"model": "admin.logentry", "pk": 119, "fields": {"action_time": "2022-02-09T11:06:04.207Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "4", "object_repr": "Django, Postgres, Gunicorn, Nginx with Docker (Part-1)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\"]}}]"}}, {"model": "admin.logentry", "pk": 120, "fields": {"action_time": "2022-02-09T11:09:42.285Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "4", "object_repr": "Django, Postgres, Gunicorn, Nginx with Docker (Part-1)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\"]}}]"}}, {"model": "admin.logentry", "pk": 121, "fields": {"action_time": "2022-02-09T11:09:48.366Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "4", "object_repr": "Django, Postgres, Gunicorn, Nginx with Docker (Part-1)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\"]}}]"}}, {"model": "admin.logentry", "pk": 122, "fields": {"action_time": "2022-02-09T11:10:07.048Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "5", "object_repr": "Django, Postgres, Gunicorn, Nginx with Docker (Part-2)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\"]}}]"}}, {"model": "admin.logentry", "pk": 123, "fields": {"action_time": "2022-02-09T11:32:03.707Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "1", "object_repr": "AI Chatbot", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Tags\"]}}]"}}, {"model": "admin.logentry", "pk": 124, "fields": {"action_time": "2022-02-09T11:33:18.599Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "4", "object_repr": "Django, Postgres, Gunicorn, Nginx with Docker (Part-1)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Tags\"]}}]"}}, {"model": "admin.logentry", "pk": 125, "fields": {"action_time": "2022-02-11T08:59:34.879Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "7", "object_repr": "Free Certbot-SSL with Nginx (HTTPS setup)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 126, "fields": {"action_time": "2022-02-11T09:26:13.870Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "1", "object_repr": "AI Chatbot", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\"]}}]"}}, {"model": "admin.logentry", "pk": 127, "fields": {"action_time": "2022-02-14T07:25:16.221Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "8", "object_repr": "OpenVPN Access Server(self-hosted) set-up on AWS EC2", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 128, "fields": {"action_time": "2022-02-14T07:27:21.040Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "6", "object_repr": "GAN(VQGAN)  + CLIP Architecture", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\", \"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 129, "fields": {"action_time": "2022-02-14T09:57:09.010Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "8", "object_repr": "OpenVPN Access Server(self-hosted) set-up on AWS EC2", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 130, "fields": {"action_time": "2022-02-14T09:58:52.593Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "8", "object_repr": "OpenVPN Access Server(self-hosted) set-up on AWS EC2", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 131, "fields": {"action_time": "2022-02-14T10:18:51.382Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "2", "object_repr": "Nepal - Covid-19 Prediction models using different ML algorithms", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\", \"Tags\"]}}]"}}, {"model": "admin.logentry", "pk": 132, "fields": {"action_time": "2022-02-14T11:45:05.845Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "8", "object_repr": "OpenVPN Access Server(self-hosted) set-up on AWS EC2", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\"]}}]"}}, {"model": "admin.logentry", "pk": 133, "fields": {"action_time": "2022-02-15T07:56:35.645Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "7", "object_repr": "Free Certbot-SSL with Nginx (HTTPS setup)", "action_flag": 3, "change_message": ""}}, {"model": "admin.logentry", "pk": 134, "fields": {"action_time": "2022-05-10T06:35:36.345Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "4", "object_repr": "Django, Postgres, Gunicorn, Nginx with Docker (Part-1)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\"]}}]"}}, {"model": "admin.logentry", "pk": 135, "fields": {"action_time": "2022-05-10T06:36:07.581Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "5", "object_repr": "Django, Postgres, Gunicorn, Nginx with Docker (Part-2)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\"]}}]"}}, {"model": "admin.logentry", "pk": 136, "fields": {"action_time": "2022-07-19T16:47:54.997Z", "user": ["sagar"], "content_type": ["experiences", "employment"], "object_id": "1", "object_repr": "VolgAI", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 137, "fields": {"action_time": "2022-07-19T16:50:50.004Z", "user": ["sagar"], "content_type": ["experiences", "employment"], "object_id": "2", "object_repr": "Genese Cl", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 138, "fields": {"action_time": "2022-07-19T16:53:46.395Z", "user": ["sagar"], "content_type": ["experiences", "employment"], "object_id": "2", "object_repr": "Genese Cloud Academy", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Company Name\", \"Position\", \"Start Year\", \"Start Month\", \"End Year\", \"End Month\", \"Description\", \"City/Town\", \"URL\"]}}]"}}, {"model": "admin.logentry", "pk": 139, "fields": {"action_time": "2022-07-19T16:58:30.047Z", "user": ["sagar"], "content_type": ["experiences", "employment"], "object_id": "3", "object_repr": "IBZ Networks Pvt. Ltd.", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 140, "fields": {"action_time": "2022-07-19T17:21:36.082Z", "user": ["sagar"], "content_type": ["experiences", "employment"], "object_id": "4", "object_repr": "Cloudyfox Technology Pvt. Ltd.", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 141, "fields": {"action_time": "2022-07-19T17:36:15.921Z", "user": ["sagar"], "content_type": ["experiences", "employment"], "object_id": "4", "object_repr": "Cloudyfox Technology Pvt. Ltd.", "action_flag": 2, "change_message": "[]"}}, {"model": "admin.logentry", "pk": 142, "fields": {"action_time": "2022-07-19T18:00:03.617Z", "user": ["sagar"], "content_type": ["experiences", "employment"], "object_id": "1", "object_repr": "VolgAI", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"City/Town\"]}}]"}}, {"model": "admin.logentry", "pk": 143, "fields": {"action_time": "2022-07-19T18:23:47.009Z", "user": ["sagar"], "content_type": ["experiences", "employment"], "object_id": "4", "object_repr": "Cloudyfox Technology Pvt. Ltd.", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Position\", \"Description\"]}}]"}}, {"model": "admin.logentry", "pk": 144, "fields": {"action_time": "2022-07-19T18:25:08.139Z", "user": ["sagar"], "content_type": ["experiences", "employment"], "object_id": "4", "object_repr": "Cloudyfox Technology Pvt. Ltd.", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Description\"]}}]"}}, {"model": "admin.logentry", "pk": 145, "fields": {"action_time": "2022-07-19T18:50:14.369Z", "user": ["sagar"], "content_type": ["experiences", "employment"], "object_id": "4", "object_repr": "Cloudyfox Technology Pvt. Ltd.", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Description\"]}}]"}}, {"model": "admin.logentry", "pk": 146, "fields": {"action_time": "2022-07-20T06:25:51.975Z", "user": ["sagar"], "content_type": ["experiences", "employment"], "object_id": "2", "object_repr": "Genese Cloud Academy", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Start Year\", \"End Year\"]}}]"}}, {"model": "admin.logentry", "pk": 147, "fields": {"action_time": "2022-07-20T06:45:33.588Z", "user": ["sagar"], "content_type": ["experiences", "employment"], "object_id": "5", "object_repr": "Freelance | Personal", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 148, "fields": {"action_time": "2022-07-20T06:48:11.535Z", "user": ["sagar"], "content_type": ["experiences", "employment"], "object_id": "5", "object_repr": "Freelance | Personal", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Description\"]}}]"}}, {"model": "admin.logentry", "pk": 149, "fields": {"action_time": "2022-07-20T06:50:28.141Z", "user": ["sagar"], "content_type": ["experiences", "employment"], "object_id": "5", "object_repr": "Freelance | Personal", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Description\"]}}]"}}, {"model": "admin.logentry", "pk": 150, "fields": {"action_time": "2022-07-20T07:21:48.170Z", "user": ["sagar"], "content_type": ["experiences", "employment"], "object_id": "6", "object_repr": "WRC", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 151, "fields": {"action_time": "2022-07-20T07:22:27.514Z", "user": ["sagar"], "content_type": ["experiences", "employment"], "object_id": "6", "object_repr": "WRC", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Description\"]}}]"}}, {"model": "admin.logentry", "pk": 152, "fields": {"action_time": "2022-07-20T07:24:05.641Z", "user": ["sagar"], "content_type": ["experiences", "employment"], "object_id": "6", "object_repr": "WRC", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Description\"]}}]"}}, {"model": "admin.logentry", "pk": 153, "fields": {"action_time": "2022-07-20T08:12:43.354Z", "user": ["sagar"], "content_type": ["experiences", "employment"], "object_id": "4", "object_repr": "Cloudyfox Technology Pvt. Ltd.", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Description\"]}}]"}}, {"model": "admin.logentry", "pk": 154, "fields": {"action_time": "2022-07-20T09:05:28.959Z", "user": ["sagar"], "content_type": ["experiences", "employment"], "object_id": "6", "object_repr": "WRC", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Description\"]}}]"}}, {"model": "admin.logentry", "pk": 155, "fields": {"action_time": "2022-07-20T09:11:04.544Z", "user": ["sagar"], "content_type": ["experiences", "employment"], "object_id": "3", "object_repr": "IBZ Networks Pvt. Ltd.", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Description\"]}}]"}}, {"model": "admin.logentry", "pk": 156, "fields": {"action_time": "2022-07-20T09:12:10.604Z", "user": ["sagar"], "content_type": ["experiences", "employment"], "object_id": "3", "object_repr": "IBZ Networks Pvt. Ltd.", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Description\"]}}]"}}, {"model": "admin.logentry", "pk": 157, "fields": {"action_time": "2022-09-18T13:26:33.219Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "6", "object_repr": "RASA Chatbot (VolgAI, Personal FAQs)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\", \"Live\", \"DownloadorView\", \"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 158, "fields": {"action_time": "2022-09-18T13:29:09.052Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "6", "object_repr": "RASA Chatbot (VolgAI, Personal FAQs)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 159, "fields": {"action_time": "2022-09-18T13:34:30.447Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "5", "object_repr": "Object Detection (IBM cloud)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\", \"Live\"]}}]"}}, {"model": "admin.logentry", "pk": 160, "fields": {"action_time": "2022-09-18T13:35:37.985Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "5", "object_repr": "Object Detection (IBM cloud)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Live\"]}}]"}}, {"model": "admin.logentry", "pk": 161, "fields": {"action_time": "2022-09-18T13:42:15.737Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "4", "object_repr": "Scrapy - Web Scraping with Python", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\", \"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 162, "fields": {"action_time": "2022-09-18T13:43:21.025Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "4", "object_repr": "Scrapy - Web Scraping with Python", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Live\"]}}]"}}, {"model": "admin.logentry", "pk": 163, "fields": {"action_time": "2022-09-18T13:44:20.083Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "4", "object_repr": "Scrapy - Web Scraping with Python", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"DownloadorView\"]}}]"}}, {"model": "admin.logentry", "pk": 164, "fields": {"action_time": "2022-09-18T13:48:20.962Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "3", "object_repr": "Text-to-Image Synthesis using GAN", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\", \"Live\", \"DownloadorView\"]}}]"}}, {"model": "admin.logentry", "pk": 165, "fields": {"action_time": "2022-09-18T13:49:07.079Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "3", "object_repr": "Text-to-Image Synthesis using GAN", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Live\", \"DownloadorView\"]}}]"}}, {"model": "admin.logentry", "pk": 166, "fields": {"action_time": "2022-09-18T13:50:01.282Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "3", "object_repr": "Text-to-Image Synthesis using GAN", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\", \"DownloadorView\"]}}]"}}, {"model": "admin.logentry", "pk": 167, "fields": {"action_time": "2022-09-18T13:52:10.972Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "1", "object_repr": "Django/Plotly - environmental sensors data handling", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\", \"Live\", \"DownloadorView\", \"Visit num\"]}}]"}}, {"model": "admin.logentry", "pk": 168, "fields": {"action_time": "2022-09-18T13:53:35.664Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "1", "object_repr": "Django/Plotly - environmental sensors data handling", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\", \"DownloadorView\"]}}]"}}, {"model": "admin.logentry", "pk": 169, "fields": {"action_time": "2022-09-18T13:54:57.302Z", "user": ["sagar"], "content_type": ["works", "work"], "object_id": "2", "object_repr": "AI Chatbot", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\", \"Live\", \"DownloadorView\"]}}]"}}, {"model": "admin.logentry", "pk": 170, "fields": {"action_time": "2022-09-18T15:56:12.820Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "6", "object_repr": "GAN(VQGAN)  + CLIP Architecture", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 171, "fields": {"action_time": "2022-09-18T15:56:43.910Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "5", "object_repr": "Django, Postgres, Gunicorn, Nginx with Docker (Part-2)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 172, "fields": {"action_time": "2022-09-18T15:57:20.546Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "4", "object_repr": "Django, Postgres, Gunicorn, Nginx with Docker (Part-1)", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 173, "fields": {"action_time": "2022-09-18T15:58:22.318Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "2", "object_repr": "Nepal - Covid-19 Prediction models using different ML algorithms", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 174, "fields": {"action_time": "2022-09-18T15:58:48.407Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "1", "object_repr": "AI Chatbot", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 175, "fields": {"action_time": "2022-09-18T16:00:02.467Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "3", "object_repr": "Simple Amazon Lex Weather Chatbot", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\", \"Tags\"]}}]"}}, {"model": "admin.logentry", "pk": 176, "fields": {"action_time": "2022-09-18T16:00:29.577Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "8", "object_repr": "OpenVPN Access Server(self-hosted) set-up on AWS EC2", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 177, "fields": {"action_time": "2022-09-18T16:05:03.047Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "8", "object_repr": "OpenVPN Access Server(self-hosted) set-up on AWS EC2", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 178, "fields": {"action_time": "2022-09-18T16:12:24.802Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "8", "object_repr": "OpenVPN Access Server(self-hosted) set-up on AWS EC2", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 179, "fields": {"action_time": "2022-09-18T16:19:53.677Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "8", "object_repr": "OpenVPN Access Server(self-hosted) set-up on AWS EC2", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 180, "fields": {"action_time": "2022-09-18T17:09:23.797Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "9", "object_repr": "Gmail with Custom Domain using Cloudflare", "action_flag": 1, "change_message": "[{\"added\": {}}]"}}, {"model": "admin.logentry", "pk": 181, "fields": {"action_time": "2022-09-19T06:37:41.819Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "9", "object_repr": "Gmail with Custom Domain using Cloudflare", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 182, "fields": {"action_time": "2022-09-19T07:04:35.899Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "9", "object_repr": "Gmail with Custom Domain using Cloudflare", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 183, "fields": {"action_time": "2022-09-19T08:19:04.557Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "6", "object_repr": "GAN(VQGAN)  + CLIP Architecture", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 184, "fields": {"action_time": "2022-09-19T08:22:35.339Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "6", "object_repr": "GAN(VQGAN)  + CLIP Architecture", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 185, "fields": {"action_time": "2022-09-19T08:25:11.731Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "6", "object_repr": "GAN(VQGAN)  + CLIP Architecture", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 186, "fields": {"action_time": "2022-09-19T08:30:06.122Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "6", "object_repr": "GAN(VQGAN)  + CLIP Architecture", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Content\"]}}]"}}, {"model": "admin.logentry", "pk": 187, "fields": {"action_time": "2022-09-20T05:41:46.198Z", "user": ["sagar"], "content_type": ["blogs", "post"], "object_id": "9", "object_repr": "Gmail with Custom Domain using Cloudflare", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Image\", \"Keywords\"]}}]"}}, {"model": "admin.logentry", "pk": 188, "fields": {"action_time": "2022-11-11T06:13:43.077Z", "user": ["sagar"], "content_type": ["experiences", "employment"], "object_id": "4", "object_repr": "Cloudyfox Technology Pvt. Ltd.", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Description\"]}}]"}}, {"model": "admin.logentry", "pk": 189, "fields": {"action_time": "2022-11-11T06:15:15.190Z", "user": ["sagar"], "content_type": ["experiences", "employment"], "object_id": "4", "object_repr": "Cloudyfox Technology Pvt. Ltd.", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Description\"]}}]"}}, {"model": "admin.logentry", "pk": 190, "fields": {"action_time": "2022-11-11T06:16:56.344Z", "user": ["sagar"], "content_type": ["experiences", "employment"], "object_id": "4", "object_repr": "Cloudyfox Technology Pvt. Ltd.", "action_flag": 2, "change_message": "[{\"changed\": {\"fields\": [\"Description\"]}}]"}}]